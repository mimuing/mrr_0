{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b4ea8fc3",
   "metadata": {},
   "source": [
    "# 0 Module import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8991c81",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "from tqdm.notebook import tqdm\n",
    "from __future__ import print_function, division\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch.backends.cudnn as cudnn\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "import albumentations\n",
    "from albumentations.imgaug.transforms import IAAAffine#, ScaleX, ScaleY\n",
    "import albumentations.pytorch\n",
    "from albumentations.core.transforms_interface import ImageOnlyTransform\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import cv2\n",
    "cudnn.benchmark = True\n",
    "from sklearn.metrics import f1_score\n",
    "import pandas as pd\n",
    "import torch\n",
    "import cv2\n",
    "from torch.nn import functional as F\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from transformers import AdamW, AutoModel, AutoTokenizer, ViTForImageClassification, ElectraModel, ElectraForSequenceClassification, ElectraTokenizer, BertForSequenceClassification, BertTokenizerFast, ViTConfig\n",
    "from transformers import AutoModel,ViTModel,ViTFeatureExtractor\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import glob\n",
    "import gc\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import random \n",
    "from transformers import AdamW\n",
    "from torchvision import transforms\n",
    "import timm\n",
    "import albumentations\n",
    "from albumentations.imgaug.transforms import IAAAffine"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d55e4b48",
   "metadata": {},
   "source": [
    "# 1. Data_Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5a29b03",
   "metadata": {},
   "outputs": [],
   "source": [
    "#한글로 이미지 읽기 쓰기\n",
    "\n",
    "def han_imread(ld_dir, color_mode = True) :\n",
    "    img_array = np.fromfile(ld_dir, np.uint8)\n",
    "    if color_mode == True :\n",
    "        img = cv2.imdecode(img_array, cv2.IMREAD_COLOR)\n",
    "    else :\n",
    "        img = cv2.imdecode(img_array, cv2.IMREAD_GRAYSCALE)\n",
    "    return img\n",
    "\n",
    "def han_imwrite(sv_dir, image) :\n",
    "    new_img_name = sv_dir\n",
    "    extension = os.path.splitext(new_img_name)[1] # 이미지 확장자\n",
    "    result, encoded_img = cv2.imencode(extension, image)\n",
    "    if result:\n",
    "        with open(new_img_name, mode='w+b') as f:\n",
    "            encoded_img.tofile(f)\n",
    "\n",
    "root_dir = 'Data/train/' # 이미지 파일이 있는 디렉토리\n",
    "os.makedirs('Data/Training_whole/PNG', exist_ok=True)\n",
    "os.makedirs('Data/Training_whole/PNG_384', exist_ok=True) # 사이즈는 훈련할때 미리 원하는 사이즈로 있어야 빠름. 원하는 preprocessing이나 사이즈는 미리 넣어주세요\n",
    "meta_dict_list = []\n",
    "i = 0\n",
    "for (root, dirs, files) in tqdm(os.walk(root_dir)): # 디렉토리 내의 모든 파일 순회\n",
    "    for file_name in tqdm(files):\n",
    "        if ('png' in file_name) or ('jpg' in file_name) or ('bmp' in file_name) : # 무슨 확장자가 있는지 몰라서 일단 썼습니다\n",
    "            \n",
    "            meta_dict = dict()\n",
    "            png_img_name = os.path.basename(root) + '_' + file_name.split('.')[0] + '.png'\n",
    "            meta_dict['id'] = i\n",
    "            meta_dict['filename'] = png_img_name\n",
    "            \n",
    "            meta_dict['label'] = os.path.basename(root)\n",
    "            meta_dict_list.append(meta_dict)\n",
    "            \n",
    "            img = han_imread(os.path.join(root, file_name))\n",
    "            img_224 = cv2.resize(img, dsize = (384, 384), interpolation = cv2.INTER_AREA)\n",
    "\n",
    "            han_imwrite( os.path.join('Data/Training_whole/PNG', png_img_name), img)\n",
    "            han_imwrite( os.path.join('Data/Training_whole/PNG_384', png_img_name), img_224)\n",
    "            i += 1\n",
    "\n",
    "meta_train = pd.DataFrame(meta_dict_list)\n",
    "meta_train.to_csv('train.csv', index = False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0c7b5ed",
   "metadata": {},
   "source": [
    "# 2. Grid_search 함수 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f371eeff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    \n",
    "CFG = {\n",
    "    'IMG_SIZE':224,\n",
    "    'EPOCHS':10,\n",
    "    'LEARNING_RATE':3e-4,\n",
    "    'BATCH_SIZE':32,\n",
    "    'SEED':41\n",
    "}\n",
    "seed_everything(CFG['SEED']) # Seed 고정\n",
    "def han_imread(ld_dir, color_mode = True) :\n",
    "    img_array = np.fromfile(ld_dir, np.uint8)\n",
    "    if color_mode == True :\n",
    "        img = cv2.imdecode(img_array, cv2.IMREAD_COLOR)\n",
    "    else :\n",
    "        img = cv2.imdecode(img_array, cv2.IMREAD_GRAYSCALE)\n",
    "    return img\n",
    "\n",
    "def han_imwrite(sv_dir, image) :\n",
    "    new_img_name = sv_dir\n",
    "    extension = os.path.splitext(new_img_name)[1] # 이미지 확장자\n",
    "    result, encoded_img = cv2.imencode(extension, image)\n",
    "    if result:\n",
    "        with open(new_img_name, mode='w+b') as f:\n",
    "            encoded_img.tofile(f)          \n",
    "\n",
    "def make_aug(meta_train_i, std_len) :\n",
    "    i_len = len(meta_train_i)\n",
    "    meta_train_i_aug = meta_train_i.copy()\n",
    "    num_concat = std_len//(i_len)-1\n",
    "    num_rand = std_len-(num_concat+1)*(i_len)\n",
    "    for n in range(num_concat) :\n",
    "        meta_train_i_aug = pd.concat((meta_train_i_aug, meta_train_i))\n",
    "\n",
    "\n",
    "    random_idx = random.sample(list(meta_train_i.index), num_rand)\n",
    "    meta_train_i_aug = pd.concat((meta_train_i_aug, meta_train_i.loc[random_idx]))\n",
    "    return meta_train_i_aug\n",
    "\n",
    "\n",
    "def train_test_split_with_aug(meta_final, num_train_list, val_num_list, save_dir = None) :\n",
    "    meta_final['task'] = 'Art'\n",
    "    task_list = sorted(np.unique(meta_final['task']))\n",
    "    # num_train = 1000\n",
    "    # num_test = 200\n",
    "    meta_test_list = []\n",
    "    meta_train_list = []\n",
    "    meta_val_list = []\n",
    "    meta_rest_list = []\n",
    "\n",
    "    for j, task in enumerate(task_list) :\n",
    "        meta_j = meta_final[meta_final['task']==task]\n",
    "        wall_list = sorted(np.unique(meta_j['class']))\n",
    "    #     aug_conunt = aug_list[j]\n",
    "        num_train = num_train_list[j]\n",
    "        num_test = val_num_list[j]\n",
    "        for i, wall in enumerate(wall_list) :\n",
    "\n",
    "            meta_i = meta_j[meta_j['class']==wall]\n",
    "            idx_list = random.sample(list(meta_i.index), len(meta_i))\n",
    "            if len(meta_i) < num_test :\n",
    "                num_test_aug = int(np.ceil(0.3 * len(meta_i)))\n",
    "                meta_test_i = meta_i.loc[idx_list[:num_test_aug]]\n",
    "                meta_test_i = make_aug(meta_test_i, num_test)\n",
    "\n",
    "                meta_val_i = meta_test_i.iloc[:int(num_test/2),:]\n",
    "                meta_test_i = meta_test_i.iloc[int(num_test/2):,:]\n",
    "                meta_train_i = meta_i.loc[idx_list[num_test_aug:]]\n",
    "                if len(meta_train_i) < num_train :\n",
    "                    meta_train_i = make_aug(meta_train_i, num_train)\n",
    "                    meta_train_i['aug'] = 'aug'\n",
    "                    print(wall, 'aug!')\n",
    "                else :\n",
    "                    meta_train_i['aug'] = 'raw'\n",
    "\n",
    "            else :\n",
    "                meta_test_i = meta_i.loc[idx_list[:num_test]]\n",
    "                meta_train_i = meta_i.loc[idx_list[num_test:]]\n",
    "                meta_val_i = meta_test_i.iloc[:int(num_test/2),:]\n",
    "                meta_test_i = meta_test_i.iloc[int(num_test/2):,:]\n",
    "                if len(meta_train_i) < num_train :\n",
    "                    print(wall, 'aug!')\n",
    "                    meta_train_i = make_aug(meta_train_i, num_train)\n",
    "                    meta_train_i['aug'] = 'aug'\n",
    "                else:\n",
    "                    meta_train_i['aug'] = 'raw'\n",
    "\n",
    "            meta_val_list = meta_val_list + [meta_val_i]\n",
    "            meta_test_list = meta_test_list + [meta_test_i]\n",
    "            meta_train_list = meta_train_list + [meta_train_i]\n",
    "    meta_val = pd.concat((meta_val_list))    \n",
    "    meta_test = pd.concat((meta_test_list))\n",
    "    meta_train = pd.concat((meta_train_list))\n",
    "    if save_dir :\n",
    "        os.makedirs(save_dir, exist_ok= True)\n",
    "        meta_train.to_csv(os.path.join(save_dir, 'train.csv'))\n",
    "        meta_test.to_csv(os.path.join(save_dir, 'test.csv'))\n",
    "        meta_val.to_csv(os.path.join(save_dir, 'val.csv'))\n",
    "    \n",
    "    \n",
    "    return meta_train, meta_val, meta_test\n",
    "    # meta_rest = pd.concat((meta_rest_list))\n",
    "\n",
    "\n",
    "\n",
    "class AugMix(ImageOnlyTransform):\n",
    "    \"\"\"Augmentations mix to Improve Robustness and Uncertainty.\n",
    "    Args:\n",
    "        image (np.ndarray): Raw input image of shape (h, w, c)\n",
    "        severity (int): Severity of underlying augmentation operators.\n",
    "        width (int): Width of augmentation chain\n",
    "        depth (int): Depth of augmentation chain. -1 enables stochastic depth uniformly\n",
    "          from [1, 3]\n",
    "        alpha (float): Probability coefficient for Beta and Dirichlet distributions.\n",
    "        augmentations (list of augmentations): Augmentations that need to mix and perform.\n",
    "    Targets:\n",
    "        image\n",
    "    Image types:\n",
    "        uint8, float32\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, width=2, depth=2, alpha=0.5, augmentations=[], always_apply=False, p=0.5):\n",
    "        super(AugMix, self).__init__(always_apply, p)\n",
    "        self.width = width\n",
    "        self.depth = depth\n",
    "        self.alpha = alpha\n",
    "        self.augmentations = augmentations\n",
    "        self.ws = np.float32(np.random.dirichlet([self.alpha] * self.width))\n",
    "        self.m = np.float32(np.random.beta(self.alpha, self.alpha))\n",
    "\n",
    "    def apply_op(self, image, op):\n",
    "        image = op(image=image)[\"image\"]\n",
    "        return image\n",
    "\n",
    "    def apply(self, img, **params):\n",
    "        mix = np.zeros_like(img)\n",
    "        for i in range(self.width):\n",
    "            image_aug = img.copy()\n",
    "\n",
    "            for _ in range(self.depth):\n",
    "                op = np.random.choice(self.augmentations)\n",
    "                image_aug = self.apply_op(image_aug, op)\n",
    "\n",
    "            mix = np.add(mix, self.ws[i] * image_aug, out=mix, casting=\"unsafe\")\n",
    "\n",
    "        mixed = (1 - self.m) * img + self.m * mix\n",
    "        if img.dtype in [\"uint8\", \"uint16\", \"uint32\", \"uint64\"]:\n",
    "            mixed = np.clip((mixed), 0, 255).astype(np.uint8)\n",
    "        return mixed\n",
    "\n",
    "    def get_transform_init_args_names(self):\n",
    "        return (\"width\", \"depth\", \"alpha\")\n",
    "\n",
    "def train_test_split_wo_aug(meta_final, split_ratio, save_dir = None) :\n",
    "    meta_final['task'] = 'Art'\n",
    "    task_list = sorted(np.unique(meta_final['task']))\n",
    "    # num_train = 1000\n",
    "    # num_test = 200\n",
    "    meta_test_list = []\n",
    "    meta_train_list = []\n",
    "    meta_val_list = []\n",
    "    meta_rest_list = []\n",
    "    \n",
    "    whole = summary(meta_final)\n",
    "    Summary_table = whole.Summary\n",
    "#     _, Summary_table, _  = make_summary(meta_final, show_fig = False) \n",
    "    Summary_table_test = (Summary_table*split_ratio).astype('int')\n",
    "    Summary_table_train = Summary_table - Summary_table_test\n",
    "    \n",
    "    \n",
    "    for j, task in enumerate(task_list) :\n",
    "        meta_j = meta_final[meta_final['task']==task]\n",
    "        wall_list = sorted(np.unique(meta_j['class']))\n",
    "    #     aug_conunt = aug_list[j]\n",
    "\n",
    "            \n",
    "        for i, wall in enumerate(wall_list) :\n",
    "\n",
    "            num_train = Summary_table_train.loc[task].loc[wall][0]\n",
    "            num_test = Summary_table_test.loc[task].loc[wall][0]\n",
    "            if num_test < 2 :\n",
    "                num_test = 1\n",
    "\n",
    "            meta_i = meta_j[meta_j['class']==wall]\n",
    "            idx_list = random.sample(list(meta_i.index), len(meta_i))\n",
    "\n",
    "            meta_test_i = meta_i.loc[idx_list[:num_test]]\n",
    "            meta_train_i = meta_i.loc[idx_list[num_test:]]\n",
    "            if num_test == 1 :\n",
    "                meta_val_i = meta_test_i.copy()\n",
    "            else : \n",
    "                meta_val_i = meta_test_i.iloc[:int(num_test/2),:]\n",
    "                meta_test_i = meta_test_i.iloc[int(num_test/2):,:]\n",
    "\n",
    "            meta_val_list = meta_val_list + [meta_val_i]\n",
    "            meta_test_list = meta_test_list + [meta_test_i]\n",
    "            meta_train_list = meta_train_list + [meta_train_i]\n",
    "    meta_val = pd.concat((meta_val_list))    \n",
    "    meta_test = pd.concat((meta_test_list))\n",
    "    meta_train = pd.concat((meta_train_list))\n",
    "    \n",
    "    if save_dir :\n",
    "        os.makedirs(save_dir, exist_ok= True)\n",
    "        meta_train.to_csv(os.path.join(save_dir, 'train.csv'))\n",
    "        meta_test.to_csv(os.path.join(save_dir, 'test.csv'))\n",
    "        meta_val.to_csv(os.path.join(save_dir, 'val.csv'))\n",
    "    \n",
    "    return meta_train, meta_val, meta_test\n",
    "    # meta_rest = pd.concat((meta_rest_list))\n",
    "\n",
    "class summary() :\n",
    "    def __init__(self, meta_final, show_fig = False) :\n",
    "        self.meta_final = meta_final\n",
    "        self.meta_final['task'] = 'Art'\n",
    "        task_list = np.unique(self.meta_final['task'])\n",
    "        task_df_dic = {}\n",
    "        image_count_dic = {}\n",
    "        count_final = 0\n",
    "        Summary_list = []\n",
    "\n",
    "        for task in task_list :\n",
    "            task_df = self.meta_final[self.meta_final['task']==task]\n",
    "            task_df_dic[task] = task_df\n",
    "            haja_list = np.unique(task_df['class'])\n",
    "            image_count = {}\n",
    "\n",
    "            for haja in haja_list :\n",
    "                Summary_dic = {}\n",
    "                image_count[haja] = len(task_df[task_df['class']==haja])\n",
    "                Summary_dic['task'] = task\n",
    "                Summary_dic['class'] = haja\n",
    "                Summary_dic['Count'] = len(task_df[task_df['class']==haja])\n",
    "                Summary_list.append(Summary_dic)\n",
    "            if show_fig == True :\n",
    "                fig1, ax1 = plt.subplots()\n",
    "                ax1.pie(image_count.values(),\n",
    "                        labels = image_count.keys(),\n",
    "                        shadow=True,\n",
    "                        autopct = '%1.1f%%',\n",
    "                        startangle=90)\n",
    "                plt.title(task+', count : {}'.format(len(task_df)))\n",
    "                plt.show()\n",
    "            else :\n",
    "                pass\n",
    "\n",
    "            count = []\n",
    "            for key, values in sorted(image_count.items()) :\n",
    "                count.append(values)\n",
    "\n",
    "            image_count_dic[task] = image_count\n",
    "            count= np.array(count)\n",
    "            count_final = count_final + count.sum()\n",
    "            ratio = count / count.max()\n",
    "            aug_list = 1/ratio\n",
    "        self.Summary_list = pd.DataFrame(Summary_list)\n",
    "        self.Summary = pd.DataFrame(Summary_list).groupby(['task','class']).sum()\n",
    "        self.Summary_mean = pd.DataFrame(Summary_list).groupby(['task']).mean()\n",
    "        self.Summary_min = pd.DataFrame(Summary_list).groupby(['task']).min().iloc[:,1:]\n",
    "        self.Summary_max = pd.DataFrame(Summary_list).groupby(['task']).max().iloc[:,1:]\n",
    "        return pd.DataFrame(Summary_list), Summary, Summary_avg, Summary_task\n",
    "\n",
    "def export_img(img_root, row, train_mode = 'val', feature_extractor = None, input_size = 224) :\n",
    "    \n",
    "    img_path = os.path.join(img_root, str(os.path.basename(row[0])))    \n",
    "    image_feature = han_imread(img_path)#cv2.imread(img_path)\n",
    "\n",
    "    if train_mode == 'train' :\n",
    "        transform = [albumentations.Resize(input_size,input_size,),\n",
    "                            albumentations.HorizontalFlip(p=0.5), albumentations.VerticalFlip(p=0.5), \n",
    "                            albumentations.RandomBrightnessContrast(brightness_limit=(-0.3, 0.3), contrast_limit=0, p=0.3),\n",
    "                            IAAAffine(scale = (0.9, 1.1), translate_percent = (0,0), rotate = (0,20), shear = 0, cval = 0, p=1.0,),\n",
    "#                             OneOf([albumentations.ShiftScaleRotate(always_apply=True), albumentations.GaussNoise(always_apply=True)]),\n",
    "                            albumentations.Cutout(always_apply=True),]\n",
    "                            #ScaleX(0.9, 1.1), ScaleY(0.9, 1.1),]) # mode = 'reflect')])#,albumentations.RandomCrop(crop_x, crop_y)]) \n",
    "        transform = albumentations.Compose([AugMix(width=3, depth=2, alpha=.2, p=1., augmentations=transform),])\n",
    "        \n",
    "        augmented = transform(image=image_feature) \n",
    "        image_feature = augmented['image']\n",
    "    elif train_mode == 'val' :\n",
    "        transform = albumentations.Compose([albumentations.Resize(input_size,input_size)])    \n",
    "        augmented = transform(image=image_feature) \n",
    "        image_feature = augmented['image']\n",
    "    elif train_mode == 'test' :\n",
    "        transform = albumentations.Compose([albumentations.Resize(input_size,input_size)])    \n",
    "        augmented = transform(image=image_feature) \n",
    "        image_feature = augmented['image']\n",
    "\n",
    "    if feature_extractor :\n",
    "        image_feature = feature_extractor(images=image_feature, return_tensors=\"pt\")\n",
    "        image_feature = image_feature['pixel_values'][0]\n",
    "    else :\n",
    "#         image_feature = cv2.resize(image_feature, (input_size, input_size), interpolation = cv2.INTER_AREA)\n",
    "        image_feature = image_feature/255\n",
    "        image_feature = np.transpose(image_feature,(2,0,1)).astype(np.float32)\n",
    "    return image_feature\n",
    "\n",
    "\n",
    "def set_parameter_requires_grad(model, feature_extracting):\n",
    "    if feature_extracting:\n",
    "        for param in model.parameters():\n",
    "            param.requires_grad = False\n",
    "            \n",
    "class img_Dataset(Dataset):\n",
    "\n",
    "    def __init__(self, df, img_root, encoder, train_mode = 'val', feature_extractor = None, input_size = 224):\n",
    "        # 일부 값중에 NaN이 있음...\n",
    "        self.dataset = df.dropna(axis=0)\n",
    "        self.img_root = img_root\n",
    "        self.train_mode = train_mode\n",
    "        self.feature_extractor = feature_extractor\n",
    "        self.input_size = input_size\n",
    "        # 중복제거\n",
    "        #self.dataset.drop_duplicates(subset=['document'], inplace=True)\n",
    "        self.dataset['label'] =  encoder.transform(self.dataset['class'])\n",
    "        self.dataset = self.dataset[['filename', 'label']]\n",
    "        #     self.tokenizer = AutoTokenizer.from_pretrained(\"monologg/koelectra-small-v2-discriminator\")\n",
    "        print('found {} data'.format(len(self.dataset)))\n",
    "        print(self.dataset.describe())\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.dataset.iloc[idx].values\n",
    "        img_path = row[0]\n",
    "        y = row[1]\n",
    "        image_feature = export_img(self.img_root, row, self.train_mode, self.feature_extractor, self.input_size) \n",
    "        return {\n",
    "            'image_feature': image_feature,\n",
    "            'y':y\n",
    "        }\n",
    "    \n",
    "    \n",
    "def infer(model, test_loader, device) :\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    batches = 0\n",
    "    total = 0\n",
    "    total_loss = 0.0\n",
    "    with torch.no_grad() :\n",
    "        for i, batch in enumerate(tqdm(test_loader)):\n",
    "            img_feature = batch['image_feature'].to(device)\n",
    "            y_batch = batch[\"y\"].to(device, dtype=torch.int64)\n",
    "            y_pred = model(img_feature)\n",
    "            _, predicted = torch.max(y_pred, 1)\n",
    "            act_vec = torch.nn.Softmax(1)(y_pred)\n",
    "            batches += 1\n",
    "            if i == 0 :\n",
    "                y_batch_whole = y_batch.cpu()\n",
    "                y_pred_whole = predicted.cpu()\n",
    "                act_vec_whole = act_vec.cpu()\n",
    "            else :\n",
    "                y_batch_whole = torch.cat((y_batch_whole, y_batch.cpu()))\n",
    "                y_pred_whole = torch.cat((y_pred_whole, predicted.cpu()))\n",
    "                act_vec_whole = torch.cat((act_vec_whole, act_vec.cpu()))\n",
    "    return y_batch_whole, y_pred_whole, act_vec_whole\n",
    "\n",
    "def train_test_split_k(df, k) :\n",
    "    df_train = df[df['kfold']!=k]\n",
    "    df_val = df[df['kfold']==k]\n",
    "    return df_train, df_val\n",
    "\n",
    "    \n",
    "def load_dataset(path, k, random_state, reset_k = False) :\n",
    "    df = pd.read_csv(path)\n",
    "    encoder = LabelEncoder()\n",
    "    encoder.fit(sorted((pd.read_csv(path))['class'].unique()))\n",
    "    if reset_k == True :\n",
    "        folds = StratifiedKFold(n_splits=k, random_state=random_state, shuffle=True)\n",
    "        df['kfold'] = -1\n",
    "        for i in range(k):\n",
    "            df_idx, valid_idx = list(folds.split(df.values, df['class']))[i]\n",
    "            valid = df.iloc[valid_idx]\n",
    "            df.loc[df[df.index.isin(valid.index) == True].index.to_list(), 'kfold'] = i\n",
    "        df.to_csv('Data/train_k.csv')\n",
    "    else :\n",
    "        pass\n",
    "    return df, encoder\n",
    "                \n",
    "# https://pytorch.org/tutorials/beginner/finetuning_torchvision_models_tutorial.html 참고\n",
    "# https://github.com/rwightman/pytorch-image-models/blob/main/results/results-imagenet-a-clean.csv timm 모델 참고\n",
    "def initialize_model(model_name, num_classes, feature_extract, use_pretrained=True, device = 'cuda'):\n",
    "    # Initialize these variables which will be set in this if statement. Each of these\n",
    "    #   variables is model specific.\n",
    "    model_ft = None\n",
    "    input_size = 0\n",
    "    \n",
    "    if model_name in ['cait_m36_384' ] :\n",
    "        model_ft = timm.create_model(model_name, pretrained=True, num_classes=num_classes)\n",
    "        input_size = 384\n",
    "        return model_ft.to(device), input_size, None\n",
    "\n",
    "\n",
    "class fine_tuning : \n",
    "    def __init__(self, img_root, exp, file, condition, cv_k, model, batch_size,  lr, decay, aug_num, save_interval,\n",
    "                 train_path, batch_size_test = 16, max_epoch = 20, early_stopping =None) : \n",
    "        \n",
    "        self.exp = exp\n",
    "        self.file = file\n",
    "        self.condition = condition\n",
    "        self.cv_k = cv_k\n",
    "        self.file_path = os.path.join(self.file, self.condition)\n",
    "        self.file_k_path = os.path.join(self.file_path, str(self.cv_k))\n",
    "        os.makedirs(self.file_k_path, exist_ok=True)\n",
    "        self.max_epoch = max_epoch\n",
    "        self.b = batch_size\n",
    "        self.d = decay\n",
    "        self.aug_num = aug_num\n",
    "        self.lr = lr\n",
    "        self.save_interval = save_interval\n",
    "        \n",
    "        df = pd.read_csv(train_path)\n",
    "        self.encoder = LabelEncoder()\n",
    "        self.encoder.fit(sorted((df)['class'].unique()))\n",
    "        \n",
    "        self.df_train, self.df_val = train_test_split_k(df, cv_k) # 0~3 까지의 값\n",
    "        \n",
    "        if self.aug_num > 1 : \n",
    "            self.df_train['task'] = 'Art'\n",
    "            self.df_train, _, _ = train_test_split_with_aug(self.df_train, [aug_num], [0], save_dir = None)\n",
    "            self.df_train = self.df_train.drop(['task', 'aug'], axis = 1)\n",
    "        \n",
    "        if torch.cuda.is_available() == True :\n",
    "            self.device = torch.device(\"cuda\")\n",
    "        else :\n",
    "            self.device = torch.device(\"cpu\")\n",
    "            \n",
    "            \n",
    "        self.model, self.input_size, self.extractor = initialize_model(model,len(self.encoder.classes_), feature_extract = False , use_pretrained=True, device = self.device)\n",
    "        train_dataset = img_Dataset(self.df_train, img_root, self.encoder, 'train', self.extractor, self.input_size)\n",
    "        val_dataset = img_Dataset(self.df_val, img_root, self.encoder, 'val', self.extractor, self.input_size)\n",
    "        \n",
    "#         self.optimizer = optimizer = AdamW(self.model.parameters(), lr=self.lr, weight_decay=self.d, correct_bias=True) # AdamW에서 bias correction 과정만 생략해주시면 BERTAdam이 됩니다!\n",
    "        self.optimizer = torch.optim.Adam(self.model.parameters(), lr=self.lr, weight_decay=self.d)\n",
    "        #self.scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(self.optimizer , mode='max', factor=0.1, patience=2, threshold=1e-7)\n",
    "        self.train_loader = DataLoader(train_dataset, batch_size=self.b, shuffle=True, num_workers = 4)\n",
    "        self.val_loader = DataLoader(val_dataset, batch_size=batch_size_test, shuffle=False, num_workers = 4)\n",
    "\n",
    "        \n",
    "    def train(self) :\n",
    "        self.history_list = []\n",
    "        best_f1_val = 0\n",
    "        \n",
    "        for i in range(self.max_epoch):\n",
    "            print(\"Epoch {}\".format(i+1))\n",
    "            history = dict()\n",
    "            loss_train, acc_train, f1_train = self.train_one_epoch(self.train_loader, True)\n",
    "            print(\"train_Loss:{:.3f}\".format(loss_train), \"train_Accuracy:{:.3f}\".format(acc_train.item()), \"train_F1:{:.3f}\".format(f1_train))\n",
    "            with torch.no_grad() :\n",
    "                loss_val, acc_val, f1_val = self.train_one_epoch(self.val_loader, False)\n",
    "            print(\"val_Loss:{:.3f}\".format(loss_val), \"val_Accuracy:{:.3f}\".format(acc_val.item()), \"val_F1:{:.3f}\".format(f1_val))\n",
    "            history['loss'] =  loss_train\n",
    "            history['accuracy'] =  acc_train.item()\n",
    "            history['f1'] =  f1_train\n",
    "            history['val_loss'] = loss_val\n",
    "            history['val_accuracy'] = acc_val.item()\n",
    "            history['val_f1'] =  f1_val\n",
    "            #self.scheduler.step(f1_val)\n",
    "            self.history_list.append(history)\n",
    "            if i % self.save_interval == 0:\n",
    "                if f1_val > best_f1_val :\n",
    "                    print('val_f1 improved!! saving model...')\n",
    "                    targetPattern = r\"{}/*.pt\".format(self.file_k_path)\n",
    "                    h5_list = glob.glob(targetPattern)\n",
    "                    if len(h5_list) >= 1 :\n",
    "                        print('previous model deleted')\n",
    "                        os.remove(h5_list[0])\n",
    "                    checkpoint_path = os.path.join(self.file_k_path,\n",
    "                                                   self.condition + '_{:02d}-{:.3f}-{:.3f}-{:.3f}.pt'.format(i, loss_val, f1_train, f1_val))#acc_val.item()))\n",
    "                    torch.save(self.model.state_dict(), checkpoint_path)\n",
    "                    best_f1_val = f1_val#acc_val.item()\n",
    "\n",
    "                else :\n",
    "                    print('val_accuracy is not improved...')\n",
    "        self.history = pd.DataFrame(self.history_list)\n",
    "\n",
    "    def train_one_epoch(self, train_loader, train_mode) :\n",
    "        if train_mode == True :\n",
    "            self.model.train()\n",
    "        else :\n",
    "            self.model.eval()\n",
    "        \n",
    "        correct = 0\n",
    "        batches = 0\n",
    "        total = 0\n",
    "        total_loss = 0.0\n",
    "        true_labels = []\n",
    "        model_preds = []\n",
    "        for batch in tqdm(train_loader):\n",
    "            self.optimizer.zero_grad()\n",
    "            img_feature = batch['image_feature'].to(self.device)\n",
    "            y_batch = batch[\"y\"].to(self.device, dtype=torch.int64)\n",
    "            y_pred = self.model(img_feature)\n",
    "            true_labels += y_batch.detach().cpu().numpy().tolist()\n",
    "            model_preds += y_pred.argmax(1).detach().cpu().numpy().tolist()\n",
    "            loss = F.cross_entropy(y_pred, y_batch)\n",
    "            if train_mode == True :\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "                \n",
    "            total_loss += loss.item() * len(y_batch)\n",
    "            _, predicted = torch.max(y_pred, 1)\n",
    "            correct += (predicted == y_batch).sum()\n",
    "            total += len(y_batch)\n",
    "            batches += 1\n",
    "            \n",
    "            if (batches % 100 == 0) and (train_mode == True) :\n",
    "                print(\"Loss:\", loss.item(), \"Accuracy:\", correct.float() / total)\n",
    "        total_loss = total_loss / len(train_loader.dataset)\n",
    "        accuracy = correct.float() / len(train_loader.dataset)\n",
    "        f1 = f1_score(true_labels, model_preds, average=\"macro\")\n",
    "        return total_loss, accuracy, f1\n",
    "\n",
    "    def save_history(self) :\n",
    "        self.show_history()\n",
    "        self.save_summary()\n",
    "        \n",
    "    def show_history(self) :\n",
    "        fig = plt.figure(figsize=(18,6))\n",
    "        ax1 = fig.add_subplot(1, 3, 1)\n",
    "        plt.plot(self.history['loss'])\n",
    "        plt.plot(self.history['val_loss'])\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Loss')\n",
    "        ax2 = fig.add_subplot(1, 3, 2)\n",
    "        plt.plot(self.history['accuracy'])\n",
    "        plt.plot(self.history['val_accuracy'])\n",
    "        plt.xlabel('Epoch')\n",
    "        ax3 = fig.add_subplot(1, 3, 3)\n",
    "        plt.plot(self.history['f1'])\n",
    "        plt.plot(self.history['val_f1'])\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('f1')\n",
    "        plt.savefig(os.path.join(self.file_k_path, 'Loss-acc-f1_plot.png'))\n",
    "        self.history.to_csv(os.path.join(self.file_k_path,'history.csv'))\n",
    "        \n",
    "        \n",
    "    def save_summary(self) :\n",
    "        A = np.array(self.history.index+1)\n",
    "        index = list(A[A%self.save_interval==0]-1)\n",
    "        Result = self.history[['loss','val_loss','accuracy','val_accuracy', 'f1', 'val_f1']].iloc[index ,:].reset_index()\n",
    "        Result['index'] = Result['index']+1\n",
    "        Result.rename(columns = {'index' : 'epoch'}, inplace = True)\n",
    "        Result['index']=self.exp\n",
    "        Result['cv_k']=self.cv_k\n",
    "        Result['batch_size']=self.b\n",
    "        Result['learning_rate']=self.lr\n",
    "        Result['L2_decay']=self.d\n",
    "        Result['aug_num']=self.aug_num\n",
    "        Result = Result[['index','cv_k', 'batch_size', 'learning_rate','L2_decay', 'aug_num', 'epoch','loss', \n",
    "                         'val_loss','accuracy','val_accuracy', 'f1','val_f1']]\n",
    "        if not ('Result.csv' in os.listdir(self.file)):\n",
    "            Result.to_csv(os.path.join(self.file,'Result.csv'))\n",
    "        else:\n",
    "            Result_0 = pd.read_csv(os.path.join(self.file,'Result.csv'), index_col=0)\n",
    "            Result = pd.concat([Result_0, Result],axis=0)\n",
    "            Result.to_csv(os.path.join(self.file,'Result.csv'))\n",
    "                    \n",
    "    def find_best_epoch(self) : \n",
    "        targetPattern = r\"{}/*.pt\".format(self.file_k_path)\n",
    "        h5_list = glob.glob(targetPattern)\n",
    "        f1_list = []\n",
    "        for h5 in h5_list:\n",
    "            f1_list.append(float(h5.split('-')[-1][:5])) \n",
    "        self.best_model_path = h5_list[(np.argmax(np.array(f1_list)))]\n",
    "        self.max_epoch = int((self.best_model_path.split('-')[-4].split('_'))[-1])\n",
    "        return np.max(np.array(f1_list))        \n",
    "\n",
    "\n",
    "class inference : \n",
    "    def __init__(self, model, encoder, file_path, cv_k, test_path, val_dataloader, model_path, max_epoch,img_root, extractor, input_size) :\n",
    "        self.encoder = encoder\n",
    "        self.cv_k = cv_k\n",
    "        self.dataframe_test = pd.read_csv(test_path)#.iloc[:,1:]\n",
    "        self.file_path = file_path\n",
    "        self.file_k_path = os.path.join(self.file_path, str(cv_k))\n",
    "        self.model_path = model_path\n",
    "        self.max_epoch  = max_epoch\n",
    "        self.test_df = pd.read_csv(test_path)\n",
    "        \n",
    "        def export_filename(x) :\n",
    "            return os.path.basename(x)\n",
    "        \n",
    "        self.test_df['filename'] = self.test_df['img_path'].apply(export_filename)\n",
    "        self.test_df['class'] = '가구수정'\n",
    "        self.sub_df = pd.read_csv('Data/sample_submission.csv')\n",
    "\n",
    "        if torch.cuda.is_available() == True :\n",
    "            self.device = torch.device(\"cuda\")\n",
    "        else :\n",
    "            self.device = torch.device(\"cpu\")\n",
    "       \n",
    "        self.model = model\n",
    "        test_dataset = img_Dataset(self.test_df, img_root, encoder, 'test', extractor, input_size)\n",
    "        self.model.load_state_dict(torch.load(self.model_path)) \n",
    "        self.test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False, num_workers = 4)\n",
    "        self.predict()\n",
    "\n",
    "    def predict(self) :\n",
    "        _, pred_test, self.act_vec_test = infer(self.model, self.test_loader, self.device) \n",
    "        pred_list = self.encoder.inverse_transform(pred_test.cpu().numpy())\n",
    "        self.test_df['class'] = pred_list \n",
    "        self.sub_df['label'] = pred_list \n",
    "        self.test_df.to_csv(os.path.join(self.file_path, 'test_cv_{}.csv'.format(self.cv_k)), index = False)\n",
    "        self.sub_df.to_csv(os.path.join(self.file_path, 'sub_cv_{}.csv'.format(self.cv_k)), index = False)                         \n",
    "\n",
    "    def pred_val(self, val_df, val_dataloader) :\n",
    "        _, pred_val, _ = infer(self.model, val_dataloader, self.device) \n",
    "        pred_val_list = self.encoder.inverse_transform(pred_val.cpu().numpy())\n",
    "        val_df['class'] = pred_val_list\n",
    "        return val_df\n",
    "\n",
    "class grid_search :\n",
    "    def __init__(self, train_path, test_path, img_root, img_test_root, file, cv_k_list, md_list, batch_size_list, lr_list, \n",
    "                 decay_list, aug_num_list, max_epoch, interval, train, initial_exp, start_exp) :\n",
    "        self.img_root = img_root\n",
    "        self.img_test_root = img_test_root\n",
    "        self.train_path = train_path  \n",
    "        self.test_path =test_path \n",
    "        self.file = file\n",
    "        self.cv_k_list = cv_k_list\n",
    "        self.md_list = md_list\n",
    "        self.batch_size_list = batch_size_list\n",
    "        self.lr_list = lr_list\n",
    "        self.decay_list = decay_list\n",
    "        self.aug_num_list = aug_num_list\n",
    "        self.max_epoch = max_epoch\n",
    "        self.save_interval = interval\n",
    "        self.train = train\n",
    "        self.exp = initial_exp\n",
    "        self.start_exp = start_exp\n",
    "        self.run()\n",
    "\n",
    "    def run(self) :\n",
    "        for md in self.md_list :\n",
    "            for b in self.batch_size_list :\n",
    "                for lr in self.lr_list : \n",
    "                    for d in self.decay_list :\n",
    "                        for aug_num in self.aug_num_list :\n",
    "\n",
    "                            self.Result = dict()\n",
    "                            self.Result_list = []\n",
    "                            self.Result['index']=self.exp\n",
    "                            self.Result['model']=md\n",
    "                            self.Result['batch_size']=b\n",
    "                            self.Result['learning_rate']=lr\n",
    "                            self.Result['L2_decay']=d\n",
    "                            self.Result['aug_num']=aug_num\n",
    "\n",
    "                            condition = '{}_md({})b({})L({})d({})an({})'.format(self.exp, md, b, lr, d, aug_num)\n",
    "                            file_path = os.path.join(self.file, condition)\n",
    "                            if self.exp < self.start_exp :\n",
    "                                print('{} passed'.format(condition))\n",
    "                                self.exp = self.exp + 1\n",
    "                                pass\n",
    "                            else :\n",
    "\n",
    "                                act_vec_list = []\n",
    "                                val_df_wrong_list = []\n",
    "                                for cv_k in self.cv_k_list : \n",
    "\n",
    "    #                                                     try :\n",
    "                                    print(condition)\n",
    "                                    self.my_bert = fine_tuning (self.img_root, self.exp, self.file, condition, cv_k,\n",
    "                                                                md, b, lr, d, aug_num, self.save_interval,\n",
    "                                                                self.train_path, batch_size_test = 16,\n",
    "                                                                max_epoch = self.max_epoch, early_stopping =None)\n",
    "\n",
    "                                    if self.train == True :\n",
    "                                        if 'history.csv' in os.listdir(self.my_bert.file_k_path) :\n",
    "                                            print('Already trained, pass!!!')\n",
    "                                        else:\n",
    "                                            self.my_bert.train()\n",
    "                                            self.my_bert.save_history()\n",
    "                                    else :\n",
    "                                        pass\n",
    "                                    max_f1 = self.my_bert.find_best_epoch()\n",
    "                                    self.Result['f1_cv_{}'.format(cv_k)] = max_f1\n",
    "\n",
    "                                    self.my_bert_inf = inference(self.my_bert.model, self.my_bert.encoder, file_path, cv_k,\n",
    "                                                                 self.test_path, self.my_bert.val_loader,\n",
    "                                                                 self.my_bert.best_model_path,\n",
    "                                                                 self.my_bert.max_epoch, self.img_test_root, self.my_bert.extractor, self.my_bert.input_size)\n",
    "\n",
    "                                    val_df_wrong = self.my_bert_inf.pred_val(self.my_bert.df_val, self.my_bert.val_loader)\n",
    "                                    val_df_wrong_list.append(val_df_wrong)\n",
    "\n",
    "\n",
    "                                    if cv_k == 0 :\n",
    "                                        act_vec_enss = self.my_bert_inf.act_vec_test.numpy().copy()\n",
    "                                    else :\n",
    "                                        act_vec_enss = act_vec_enss + self.my_bert_inf.act_vec_test.numpy()\n",
    "\n",
    "                                val_df_wrong = pd.concat(val_df_wrong_list)\n",
    "                                val_df_wrong.sort_values('id')\n",
    "                                val_df_wrong.to_excel(os.path.join(self.my_bert.file_path, 'train_df_wrong.xlsx'), index = False)\n",
    "\n",
    "                                act_vec_enss = act_vec_enss / 4\n",
    "                                pred_enss = np.argmax(act_vec_enss, 1)\n",
    "                                pred_list = self.my_bert.encoder.inverse_transform(pred_enss)\n",
    "                                self.my_bert_inf.sub_df['label'] = pred_list\n",
    "                                self.my_bert_inf.sub_df.to_csv(os.path.join(self.my_bert.file_path, 'sub_cv_enss.csv'), index = False)  \n",
    "                                self.Summary = pd.DataFrame([self.Result])\n",
    "                                if 'Summary_cv.xlsx' in os.listdir(self.file) :\n",
    "                                    Summary_0 = pd.read_excel(os.path.join(self.file, 'Summary_cv.xlsx'), engine='openpyxl')\n",
    "                                    self.Summary = pd.concat((Summary_0, self.Summary))\n",
    "                                    self.Summary = self.Summary.drop_duplicates('index', keep='last')\n",
    "                                    self.Summary.to_excel(os.path.join(self.file, 'Summary_cv.xlsx'), index = False)\n",
    "                                else : \n",
    "                                    self.Summary.to_excel(os.path.join(self.file, 'Summary_cv.xlsx'), index = False)\n",
    "\n",
    "\n",
    "\n",
    "                                self.exp = self.exp + 1\n",
    "\n",
    "                                gc.collect()\n",
    "                                torch.cuda.reset_max_memory_allocated(device=torch.device(\"cuda\"))\n",
    "                                torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cae5eae",
   "metadata": {},
   "source": [
    "\n",
    "# 3. Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4117a102",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# from train_torch_augmix import *\n",
    "if __name__ == '__main__' :\n",
    "    \n",
    "    train_path = r\"Data/train_k.csv\"\n",
    "    test_path = r\"Data/test.csv\"\n",
    "    img_root = r\"Data/Training_whole/PNG_384\"\n",
    "    img_test_root = r\"Data/test\"\n",
    "    file = 'training/exp_cait_m36_384_ft_augmix'\n",
    "    cv_k_list = [0, 1, 2, 3]\n",
    "    model_list = ['cait_m36_384']\n",
    "\n",
    "    lr_list = [1e-6]#, \n",
    "    decay_list = [0]#,\n",
    "    batch_size_list = [1]\n",
    "    aug_num_list = [900]\n",
    "    max_epoch = 6\n",
    "    interval = 1\n",
    "    train = True\n",
    "    initial_exp = 0\n",
    "    start_exp = 0\n",
    "\n",
    "    my_gs = grid_search(train_path, test_path, img_root, img_test_root, file, cv_k_list, model_list, batch_size_list, lr_list,\n",
    "                        decay_list, aug_num_list, max_epoch, interval, train, initial_exp, start_exp)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch113_38",
   "language": "python",
   "name": "torch113_38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
