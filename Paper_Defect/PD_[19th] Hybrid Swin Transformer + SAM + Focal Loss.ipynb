{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y8JVqk4vQ7lf",
        "outputId": "239874cf-317a-4c8f-9cd7-59670c6fbe2c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# 구글 드라이브 마운트\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "UUnjaTyqFMIi"
      },
      "outputs": [],
      "source": [
        "from glob import glob\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "import random\n",
        "import albumentations as A\n",
        "from PIL import Image\n",
        "import cv2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qdIV5fkEmpFc",
        "outputId": "ce2a3213-b0b8-485d-e169-fe8272c400e6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Device: grpc://10.3.238.74:8470\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:`tf.distribute.experimental.TPUStrategy` is deprecated, please use  the non experimental symbol `tf.distribute.TPUStrategy` instead.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of replicas 8\n",
            "2.12.0\n",
            "TFRecord Files: 0\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import backend\n",
        "from tensorflow.keras import layers\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "tf.config.set_soft_device_placement(True)\n",
        "\n",
        "try:\n",
        "  tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
        "  print('Device:', tpu.master())\n",
        "  tf.config.experimental_connect_to_cluster(tpu)\n",
        "  tf.tpu.experimental.initialize_tpu_system(tpu)\n",
        "  strategy = tf.distribute.experimental.TPUStrategy(tpu)\n",
        "except:\n",
        "  strategy = tf.distribute.get_strategy()\n",
        "print('Number of replicas', strategy.num_replicas_in_sync)\n",
        "\n",
        "Autotune = tf.data.experimental.AUTOTUNE\n",
        "\n",
        "print(tf.__version__)\n",
        "\n",
        "GCS_PATH = \"gs://hoon_bari\"\n",
        "\n",
        "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
        "\n",
        "file_path = tf.io.gfile.glob(str(GCS_PATH + '/Dacon_wallpaper/*.tfrec'))\n",
        "# 파일 갯수 확인\n",
        "print('TFRecord Files:', len(file_path))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 랜덤 시드 설정\n",
        "seed_value = 1337\n",
        "\n",
        "# Python의 시드 설정\n",
        "random.seed(seed_value)\n",
        "\n",
        "# Numpy의 시드 설정\n",
        "np.random.seed(seed_value)\n",
        "\n",
        "# TensorFlow의 시드 설정\n",
        "tf.random.set_seed(seed_value)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bE2HTNJyC_WR",
        "outputId": "d362a995-8242-4360-ad16-7f8770eb208b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found existing installation: Pillow 8.4.0\n",
            "Uninstalling Pillow-8.4.0:\n",
            "  Successfully uninstalled Pillow-8.4.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pillow-simd\n",
            "  Downloading Pillow-SIMD-9.0.0.post1.tar.gz (849 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m849.9/849.9 kB\u001b[0m \u001b[31m14.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: pillow-simd\n",
            "  Building wheel for pillow-simd (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pillow-simd: filename=Pillow_SIMD-9.0.0.post1-cp310-cp310-linux_x86_64.whl size=1446037 sha256=0e02ec0315f790b5f253963f17b93e35dde57ec4196e19e654e58cfb5c764c0f\n",
            "  Stored in directory: /root/.cache/pip/wheels/5b/40/80/c3580fdb22f9cc7362b26cac344b501994785f96329a3f6b94\n",
            "Successfully built pillow-simd\n",
            "Installing collected packages: pillow-simd\n",
            "Successfully installed pillow-simd-9.0.0.post1\n"
          ]
        }
      ],
      "source": [
        "!pip uninstall -y pillow\n",
        "!CC=\"cc -mavx2\" pip install -U --force-reinstall pillow-simd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nQIkSIwdnmJ1"
      },
      "outputs": [],
      "source": [
        "# 설치 후 런타임 재실행\n",
        "!sudo apt-get install -y fonts-nanum\n",
        "!sudo fc-cache -fv\n",
        "!rm ~/.cache/matplotlib -rf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7W4tXKML2FK7"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.rcParams['font.family'] = 'NanumGothic'\n",
        "plt.rcParams['axes.unicode_minus'] = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gIKWPLoPgmeE"
      },
      "outputs": [],
      "source": [
        "base_dir = '/content/drive/MyDrive/Dacon_wallpaper/'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "52YHEUqqgvI3"
      },
      "outputs": [],
      "source": [
        "train_folder = glob(base_dir + 'train/*')\n",
        "\n",
        "train_path = []\n",
        "for folder in train_folder:\n",
        "    tmp = glob(folder + '/*')\n",
        "    train_path += tmp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "18af_bobgzk7",
        "outputId": "22c487e1-904d-4671-925e-60ba566cd3dc"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-d795850f-4709-449d-a42b-c7f7f9de7da3\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>path</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>/content/drive/MyDrive/Dacon_wallpaper/train/ᄀ...</td>\n",
              "      <td>걸레받이수정</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>/content/drive/MyDrive/Dacon_wallpaper/train/ᄀ...</td>\n",
              "      <td>걸레받이수정</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>/content/drive/MyDrive/Dacon_wallpaper/train/ᄀ...</td>\n",
              "      <td>걸레받이수정</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>/content/drive/MyDrive/Dacon_wallpaper/train/ᄀ...</td>\n",
              "      <td>걸레받이수정</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>/content/drive/MyDrive/Dacon_wallpaper/train/ᄀ...</td>\n",
              "      <td>걸레받이수정</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3452</th>\n",
              "      <td>/content/drive/MyDrive/Dacon_wallpaper/train/ᄒ...</td>\n",
              "      <td>훼손</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3453</th>\n",
              "      <td>/content/drive/MyDrive/Dacon_wallpaper/train/ᄒ...</td>\n",
              "      <td>훼손</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3454</th>\n",
              "      <td>/content/drive/MyDrive/Dacon_wallpaper/train/ᄒ...</td>\n",
              "      <td>훼손</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3455</th>\n",
              "      <td>/content/drive/MyDrive/Dacon_wallpaper/train/ᄒ...</td>\n",
              "      <td>훼손</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3456</th>\n",
              "      <td>/content/drive/MyDrive/Dacon_wallpaper/train/ᄒ...</td>\n",
              "      <td>훼손</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3457 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d795850f-4709-449d-a42b-c7f7f9de7da3')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-d795850f-4709-449d-a42b-c7f7f9de7da3 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-d795850f-4709-449d-a42b-c7f7f9de7da3');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                                   path            label\n",
              "0     /content/drive/MyDrive/Dacon_wallpaper/train/ᄀ...  걸레받이수정\n",
              "1     /content/drive/MyDrive/Dacon_wallpaper/train/ᄀ...  걸레받이수정\n",
              "2     /content/drive/MyDrive/Dacon_wallpaper/train/ᄀ...  걸레받이수정\n",
              "3     /content/drive/MyDrive/Dacon_wallpaper/train/ᄀ...  걸레받이수정\n",
              "4     /content/drive/MyDrive/Dacon_wallpaper/train/ᄀ...  걸레받이수정\n",
              "...                                                 ...              ...\n",
              "3452  /content/drive/MyDrive/Dacon_wallpaper/train/ᄒ...            훼손\n",
              "3453  /content/drive/MyDrive/Dacon_wallpaper/train/ᄒ...            훼손\n",
              "3454  /content/drive/MyDrive/Dacon_wallpaper/train/ᄒ...            훼손\n",
              "3455  /content/drive/MyDrive/Dacon_wallpaper/train/ᄒ...            훼손\n",
              "3456  /content/drive/MyDrive/Dacon_wallpaper/train/ᄒ...            훼손\n",
              "\n",
              "[3457 rows x 2 columns]"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_df = pd.DataFrame(train_path, columns=['path'])\n",
        "train_df['label'] = train_df['path'].apply(lambda x: x.split('/')[-2])\n",
        "train_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BXWh8Z-yg6Um",
        "outputId": "b2dc8e40-388b-41d7-d836-9cc3b6bc40b9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "훼손                 1405\n",
              "오염                  595\n",
              "걸레받이수정        307\n",
              "꼬임                  210\n",
              "터짐                  162\n",
              "곰팡이               145\n",
              "오타공                142\n",
              "몰딩수정            130\n",
              "면불량               99\n",
              "석고수정              57\n",
              "들뜸                  54\n",
              "피스                    51\n",
              "창틀,문틀수정      27\n",
              "울음                  22\n",
              "이음부불량           17\n",
              "녹오염                14\n",
              "가구수정               12\n",
              "틈새과다                5\n",
              "반점                   3\n",
              "Name: label, dtype: int64"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_df['label'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aMg5luWy26SZ"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "label_counts = train_df['label'].value_counts()\n",
        "plt.bar(range(len(label_counts)), label_counts.values)\n",
        "plt.xticks(range(len(label_counts)), label_counts.index)\n",
        "plt.xlabel('Class')\n",
        "plt.ylabel('Number of Images')\n",
        "plt.title('Distribution of Train Dataset')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7bPTtNCciNUi"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize = (15,12))\n",
        "for idx, i in enumerate(train_df.label.unique()):\n",
        "    plt.subplot(4, 7, idx+1)\n",
        "    df = train_df[train_df['label'] == i].reset_index(drop = True)\n",
        "    # image_path = df.loc[random.randint(0, len(df))-1, 'path']\n",
        "    image_path = df.loc[random.randint(0, len(df)-1), 'path']\n",
        "    img = Image.open(image_path)\n",
        "    img = img.resize((224,224))\n",
        "    plt.imshow(img)\n",
        "    plt.axis('off')\n",
        "    plt.title(i)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lDcjfkCDBdel",
        "outputId": "84961a03-58d7-42fc-af09-083c4bcaf393"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 19/19 [09:46<00:00, 30.86s/it]\n"
          ]
        }
      ],
      "source": [
        "# augmentation 데이터셋 생성기\n",
        "transform = A.Compose([\n",
        "    A.ShiftScaleRotate(scale_limit=(0, 0.1), p=0.7),\n",
        "    A.RandomBrightnessContrast(brightness_limit=[-0.3, 0.1], contrast_limit=[-0.3, 0.1], p=1),\n",
        "    A.HorizontalFlip(p=0.5),\n",
        "    A.GaussNoise(var_limit=(10, 50), p=0.5),\n",
        "    A.CoarseDropout(p=0.3, max_holes=15, max_height=15, max_width=15),\n",
        "    A.OneOf([\n",
        "        A.CLAHE(p=0.7),\n",
        "        A.ToGray(p=0.1),\n",
        "        A.Blur(blur_limit=(5, 10), p=0.2)\n",
        "    ], p=1)\n",
        "])\n",
        "\n",
        "# augmentation을 적용할 클래스 폴더들\n",
        "class_folders = ['가구수정', '걸레받이수정', '곰팡이', '꼬임', '오염', '녹오염', '들뜸', '면불량', '몰딩수정', '반점', '석고수정', '오타공', '울음', '이음부불량', '창틀,문틀수정', '터짐', '틈새과다', '피스', '훼손']\n",
        "\n",
        "# augmentation을 적용할 클래스 폴더들을 순회하며 augmentation 적용\n",
        "for class_folder in tqdm(class_folders):\n",
        "    # 클래스 폴더 경로\n",
        "    class_dir = f'/content/drive/MyDrive/Dacon_wallpaper/train/{class_folder}'\n",
        "\n",
        "    # augmentation된 이미지를 저장할 디렉토리 경로\n",
        "    aug_dir = f'/content/drive/MyDrive/Dacon_wallpaper/train_augmented/{class_folder}'\n",
        "\n",
        "    # 폴더 생성\n",
        "    if not os.path.exists(aug_dir):\n",
        "        os.makedirs(aug_dir)\n",
        "\n",
        "    if class_folder == '훼손':\n",
        "        num = 0\n",
        "        aug = 1705 - len(os.listdir(class_dir))\n",
        "        while num < aug: \n",
        "            for idx, filename in enumerate(os.listdir(class_dir)):\n",
        "                # 이미지 파일을 불러와 augmentation 적용\n",
        "                img_path = os.path.join(class_dir, filename)\n",
        "                img = np.array(Image.open(img_path))\n",
        "                augmented = transform(image=img)\n",
        "                img_augmented = augmented['image']\n",
        "\n",
        "                # augmentation된 이미지 저장\n",
        "                Image.fromarray(img_augmented).save(os.path.join(aug_dir, f'augmented_{num+1}.png'))\n",
        "                num += 1\n",
        "                if num == aug:\n",
        "                    break\n",
        "\n",
        "    elif class_folder == '오염':\n",
        "        num = 0\n",
        "        aug = 895 - len(os.listdir(class_dir))\n",
        "        while num < aug: \n",
        "            for idx, filename in enumerate(os.listdir(class_dir)):\n",
        "                # 이미지 파일을 불러와 augmentation 적용\n",
        "                img_path = os.path.join(class_dir, filename)\n",
        "                img = np.array(Image.open(img_path))\n",
        "                augmented = transform(image=img)\n",
        "                img_augmented = augmented['image']\n",
        "\n",
        "                # augmentation된 이미지 저장\n",
        "                Image.fromarray(img_augmented).save(os.path.join(aug_dir, f'augmented_{num+1}.png'))\n",
        "                num += 1\n",
        "                if num == aug:\n",
        "                    break\n",
        "\n",
        "    elif class_folder == '걸레받이수정':\n",
        "        num = 0\n",
        "        aug = 500 - len(os.listdir(class_dir))\n",
        "        while num < aug: \n",
        "            for idx, filename in enumerate(os.listdir(class_dir)):\n",
        "                # 이미지 파일을 불러와 augmentation 적용\n",
        "                img_path = os.path.join(class_dir, filename)\n",
        "                img = np.array(Image.open(img_path))\n",
        "                augmented = transform(image=img)\n",
        "                img_augmented = augmented['image']\n",
        "\n",
        "                # augmentation된 이미지 저장\n",
        "                Image.fromarray(img_augmented).save(os.path.join(aug_dir, f'augmented_{num+1}.png'))\n",
        "                num += 1\n",
        "                if num == aug:\n",
        "                    break\n",
        "\n",
        "        \n",
        "    elif class_folder == '꼬임':\n",
        "        num = 0\n",
        "        aug = 400 - len(os.listdir(class_dir))\n",
        "        while num < aug: \n",
        "            for idx, filename in enumerate(os.listdir(class_dir)):\n",
        "                # 이미지 파일을 불러와 augmentation 적용\n",
        "                img_path = os.path.join(class_dir, filename)\n",
        "                img = np.array(Image.open(img_path))\n",
        "                augmented = transform(image=img)\n",
        "                img_augmented = augmented['image']\n",
        "\n",
        "                # augmentation된 이미지 저장\n",
        "                Image.fromarray(img_augmented).save(os.path.join(aug_dir, f'augmented_{num+1}.png'))\n",
        "                num += 1\n",
        "                if num == aug:\n",
        "                    break\n",
        "    \n",
        "    elif class_folder == '터짐':\n",
        "        num = 0\n",
        "        aug = 350 - len(os.listdir(class_dir))\n",
        "        while num < aug: \n",
        "            for idx, filename in enumerate(os.listdir(class_dir)):\n",
        "                # 이미지 파일을 불러와 augmentation 적용\n",
        "                img_path = os.path.join(class_dir, filename)\n",
        "                img = np.array(Image.open(img_path))\n",
        "                augmented = transform(image=img)\n",
        "                img_augmented = augmented['image']\n",
        "\n",
        "                # augmentation된 이미지 저장\n",
        "                Image.fromarray(img_augmented).save(os.path.join(aug_dir, f'augmented_{num+1}.png'))\n",
        "                num += 1\n",
        "                if num == aug:\n",
        "                    break\n",
        "\n",
        "    elif class_folder == '곰팡이' or class_folder == '오타공' or class_folder == '몰딩수정' or class_folder == '면불량' or class_folder == '석고수정':\n",
        "        num = 0\n",
        "        aug = 300 - len(os.listdir(class_dir))\n",
        "        while num < aug: \n",
        "            for idx, filename in enumerate(os.listdir(class_dir)):\n",
        "                # 이미지 파일을 불러와 augmentation 적용\n",
        "                img_path = os.path.join(class_dir, filename)\n",
        "                img = np.array(Image.open(img_path))\n",
        "                augmented = transform(image=img)\n",
        "                img_augmented = augmented['image']\n",
        "\n",
        "                # augmentation된 이미지 저장\n",
        "                Image.fromarray(img_augmented).save(os.path.join(aug_dir, f'augmented_{num+1}.png'))\n",
        "                num += 1\n",
        "                if num == aug:\n",
        "                    break\n",
        "\n",
        "\n",
        "    elif class_folder == '들뜸' or class_folder == '피스' or class_folder == '울음' or class_folder == '창틀,문틀수정':\n",
        "        num = 0\n",
        "        aug = 200 - len(os.listdir(class_dir))\n",
        "        while num < aug: \n",
        "            for idx, filename in enumerate(os.listdir(class_dir)):\n",
        "                # 이미지 파일을 불러와 augmentation 적용\n",
        "                img_path = os.path.join(class_dir, filename)\n",
        "                img = np.array(Image.open(img_path))\n",
        "                augmented = transform(image=img)\n",
        "                img_augmented = augmented['image']\n",
        "\n",
        "                # augmentation된 이미지 저장\n",
        "                Image.fromarray(img_augmented).save(os.path.join(aug_dir, f'augmented_{num+1}.png'))\n",
        "                num += 1\n",
        "                if num == aug:\n",
        "                    break\n",
        "    \n",
        "    elif class_folder == '이음부불량' or class_folder == '가구수정' or class_folder == '틈새과다':\n",
        "        num = 0\n",
        "        aug = 150 - len(os.listdir(class_dir))\n",
        "        while num < aug: \n",
        "            for idx, filename in enumerate(os.listdir(class_dir)):\n",
        "                # 이미지 파일을 불러와 augmentation 적용\n",
        "                img_path = os.path.join(class_dir, filename)\n",
        "                img = np.array(Image.open(img_path))\n",
        "                augmented = transform(image=img)\n",
        "                img_augmented = augmented['image']\n",
        "\n",
        "                # augmentation된 이미지 저장\n",
        "                Image.fromarray(img_augmented).save(os.path.join(aug_dir, f'augmented_{num+1}.png'))\n",
        "                num += 1\n",
        "                if num == aug:\n",
        "                    break\n",
        "    \n",
        "    elif class_folder == '녹오염':\n",
        "        num = 0\n",
        "        aug = 100 - len(os.listdir(class_dir))\n",
        "        while num < aug: \n",
        "            for idx, filename in enumerate(os.listdir(class_dir)):\n",
        "                # 이미지 파일을 불러와 augmentation 적용\n",
        "                img_path = os.path.join(class_dir, filename)\n",
        "                img = np.array(Image.open(img_path))\n",
        "                augmented = transform(image=img)\n",
        "                img_augmented = augmented['image']\n",
        "\n",
        "                # augmentation된 이미지 저장\n",
        "                Image.fromarray(img_augmented).save(os.path.join(aug_dir, f'augmented_{num+1}.png'))\n",
        "                num += 1\n",
        "                if num == aug:\n",
        "                    break\n",
        "\n",
        "    elif class_folder == '반점':\n",
        "        num = 0\n",
        "        aug = 100 - len(os.listdir(class_dir))\n",
        "        while num < aug: \n",
        "            for idx, filename in enumerate(os.listdir(class_dir)):\n",
        "                # 이미지 파일을 불러와 augmentation 적용\n",
        "                img_path = os.path.join(class_dir, filename)\n",
        "                img = np.array(Image.open(img_path))\n",
        "                augmented = transform(image=img)\n",
        "                img_augmented = augmented['image']\n",
        "\n",
        "                # augmentation된 이미지 저장\n",
        "                Image.fromarray(img_augmented).save(os.path.join(aug_dir, f'augmented_{num+1}.png'))\n",
        "                num += 1\n",
        "                if num == aug:\n",
        "                    break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6o5hN6LZpdyX",
        "outputId": "5f074226-9602-491c-f405-284c181c4a9e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "훼손                 300\n",
              "오염                 300\n",
              "석고수정            243\n",
              "면불량             201\n",
              "걸레받이수정       193\n",
              "꼬임                 190\n",
              "터짐                 188\n",
              "울음                178\n",
              "창틀,문틀수정    173\n",
              "몰딩수정           170\n",
              "오타공               158\n",
              "곰팡이              155\n",
              "피스                  149\n",
              "들뜸                146\n",
              "틈새과다             145\n",
              "가구수정             138\n",
              "이음부불량         133\n",
              "반점                 97\n",
              "녹오염               86\n",
              "Name: label, dtype: int64"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# augmentation data 개수 확인\n",
        "aug_folder = glob(base_dir + 'train_augmented/*')\n",
        "\n",
        "aug_path = []\n",
        "for folder in aug_folder:\n",
        "    tmp = glob(folder + '/*')\n",
        "    aug_path += tmp\n",
        "\n",
        "aug_df = pd.DataFrame(aug_path, columns=['path'])\n",
        "aug_df['label'] = aug_df['path'].apply(lambda x: x.split('/')[-2])\n",
        "aug_df['label'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "O0JOvUUlBdIw",
        "outputId": "2f081d75-ef08-464d-c39c-d5282562b0be"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-a35892dd-e850-458b-bd28-08736d2becf7\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>path</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>/content/drive/MyDrive/Dacon_wallpaper/train/ᄀ...</td>\n",
              "      <td>걸레받이수정</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>/content/drive/MyDrive/Dacon_wallpaper/train/ᄀ...</td>\n",
              "      <td>걸레받이수정</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>/content/drive/MyDrive/Dacon_wallpaper/train/ᄀ...</td>\n",
              "      <td>걸레받이수정</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>/content/drive/MyDrive/Dacon_wallpaper/train/ᄀ...</td>\n",
              "      <td>걸레받이수정</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>/content/drive/MyDrive/Dacon_wallpaper/train/ᄀ...</td>\n",
              "      <td>걸레받이수정</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6795</th>\n",
              "      <td>/content/drive/MyDrive/Dacon_wallpaper/train_a...</td>\n",
              "      <td>훼손</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6796</th>\n",
              "      <td>/content/drive/MyDrive/Dacon_wallpaper/train_a...</td>\n",
              "      <td>훼손</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6797</th>\n",
              "      <td>/content/drive/MyDrive/Dacon_wallpaper/train_a...</td>\n",
              "      <td>훼손</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6798</th>\n",
              "      <td>/content/drive/MyDrive/Dacon_wallpaper/train_a...</td>\n",
              "      <td>훼손</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6799</th>\n",
              "      <td>/content/drive/MyDrive/Dacon_wallpaper/train_a...</td>\n",
              "      <td>훼손</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>6800 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a35892dd-e850-458b-bd28-08736d2becf7')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-a35892dd-e850-458b-bd28-08736d2becf7 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-a35892dd-e850-458b-bd28-08736d2becf7');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                                   path            label\n",
              "0     /content/drive/MyDrive/Dacon_wallpaper/train/ᄀ...  걸레받이수정\n",
              "1     /content/drive/MyDrive/Dacon_wallpaper/train/ᄀ...  걸레받이수정\n",
              "2     /content/drive/MyDrive/Dacon_wallpaper/train/ᄀ...  걸레받이수정\n",
              "3     /content/drive/MyDrive/Dacon_wallpaper/train/ᄀ...  걸레받이수정\n",
              "4     /content/drive/MyDrive/Dacon_wallpaper/train/ᄀ...  걸레받이수정\n",
              "...                                                 ...              ...\n",
              "6795  /content/drive/MyDrive/Dacon_wallpaper/train_a...            훼손\n",
              "6796  /content/drive/MyDrive/Dacon_wallpaper/train_a...            훼손\n",
              "6797  /content/drive/MyDrive/Dacon_wallpaper/train_a...            훼손\n",
              "6798  /content/drive/MyDrive/Dacon_wallpaper/train_a...            훼손\n",
              "6799  /content/drive/MyDrive/Dacon_wallpaper/train_a...            훼손\n",
              "\n",
              "[6800 rows x 2 columns]"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 총 파일 개수 확인\n",
        "df = pd.concat([train_df, aug_df], ignore_index=True)\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "G0cnXD8kSOyV"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# 학습 데이터셋 경로\n",
        "train_img_dir = '/content/drive/MyDrive/Dacon_wallpaper/train/'\n",
        "\n",
        "# augmentation 데이터셋 경로\n",
        "aug_train_img_dir = '/content/drive/MyDrive/Dacon_wallpaper/train_augmented/'\n",
        "\n",
        "# 이미지 크기 설정\n",
        "img_width, img_height = 384, 384\n",
        "\n",
        "# 데이터셋 경로와 레이블 추출\n",
        "dataset_paths = []\n",
        "labels = []\n",
        "\n",
        "for label in os.listdir(train_img_dir):\n",
        "    label_path = os.path.join(train_img_dir, label)\n",
        "    img_files = os.listdir(label_path)\n",
        "\n",
        "    if label == '훼손':\n",
        "        label_path = os.path.join(train_img_dir, label)\n",
        "        img_files = os.listdir(label_path)\n",
        "        img_files = random.sample(img_files, min(800, len(img_files)))\n",
        "        for img_file in img_files:\n",
        "            img_path = os.path.join(label_path, img_file)\n",
        "            dataset_paths.append(img_path)\n",
        "            labels.append(label)\n",
        "\n",
        "    elif label == '오염':\n",
        "        label_path = os.path.join(train_img_dir, label)\n",
        "        img_files = os.listdir(label_path)\n",
        "        img_files = random.sample(img_files, min(400, len(img_files)))\n",
        "        for img_file in img_files:\n",
        "            img_path = os.path.join(label_path, img_file)\n",
        "            dataset_paths.append(img_path)\n",
        "            labels.append(label)\n",
        "        \n",
        "    else:\n",
        "        label_path = os.path.join(train_img_dir, label)\n",
        "        for img_file in os.listdir(label_path):\n",
        "            img_path = os.path.join(label_path, img_file)\n",
        "            dataset_paths.append(img_path)\n",
        "            labels.append(label)\n",
        "\n",
        "\n",
        "for label in os.listdir(aug_train_img_dir):\n",
        "    label_path = os.path.join(aug_train_img_dir, label)\n",
        "    for img_file in os.listdir(label_path):\n",
        "        img_path = os.path.join(label_path, img_file)\n",
        "        dataset_paths.append(img_path)\n",
        "        labels.append(label)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RiYESv7z9PAE",
        "outputId": "bd5bd7d6-d012-46ad-f284-4f40ce4e2de9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "6000"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(dataset_paths) # 6000장 확인"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l_hacACsNPx0",
        "outputId": "96c3885c-a79f-41c5-8b72-31dc0ff09bf9"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 6000/6000 [03:11<00:00, 31.41it/s]\n"
          ]
        }
      ],
      "source": [
        "# 데이터 셋 불러오기\n",
        "def load_dataset(dataset_paths, img_width, img_height):\n",
        "    x_data = []\n",
        "    for path in tqdm(dataset_paths):\n",
        "        img = Image.open(path)\n",
        "        img = img.resize((img_width, img_height))\n",
        "        img = np.asarray(img)\n",
        "        # 이미지 전처리\n",
        "        img = tf.keras.applications.efficientnet_v2.preprocess_input(img)\n",
        "        x_data.append(img)\n",
        "\n",
        "    x_data = np.array(x_data)\n",
        "    return x_data\n",
        "\n",
        "x_data = load_dataset(dataset_paths, img_width, img_height)\n",
        "y_data = np.array(labels)\n",
        "\n",
        "# 레이블 인코딩\n",
        "le = LabelEncoder()\n",
        "y_encoded = le.fit_transform(y_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "m6HeVwC0vvx-"
      },
      "outputs": [],
      "source": [
        "# hybrid Model(efficientNet, swin, 출처 : https://github.com/innat/HybridModel-GradCAM/blob/main/notebooks/%5BColab%5D_HENetSwinT.ipynb)\n",
        "\n",
        "patch_size      = (2,2)   # 2-by-2 sized patches\n",
        "dropout_rate    = 0.5     # Dropout rate\n",
        "num_heads       = 8       # Attention heads\n",
        "embed_dim       = 64      # Embedding dimension\n",
        "num_mlp         = 128     # MLP layer size\n",
        "qkv_bias        = True    # Convert embedded patches to query, key, and values\n",
        "window_size     = 2       # Size of attention window\n",
        "shift_size      = 1       # Size of shifting window\n",
        "image_dimension = 24      # Initial image size / Input size of the transformer model \n",
        "\n",
        "num_patch_x = image_dimension // patch_size[0]\n",
        "num_patch_y = image_dimension // patch_size[1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "xCl6ODlOv7UD"
      },
      "outputs": [],
      "source": [
        "def window_partition(x, window_size):\n",
        "    _, height, width, channels = x.shape\n",
        "    patch_num_y = height // window_size\n",
        "    patch_num_x = width // window_size\n",
        "    x = tf.reshape(\n",
        "        x, shape=(-1, patch_num_y, window_size, patch_num_x, window_size, channels)\n",
        "    )\n",
        "    x = tf.transpose(x, (0, 1, 3, 2, 4, 5))\n",
        "    windows = tf.reshape(x, shape=(-1, window_size, window_size, channels))\n",
        "    return windows\n",
        "\n",
        "\n",
        "def window_reverse(windows, window_size, height, width, channels):\n",
        "    patch_num_y = height // window_size\n",
        "    patch_num_x = width // window_size\n",
        "    x = tf.reshape(\n",
        "        windows,\n",
        "        shape=(-1, patch_num_y, patch_num_x, window_size, window_size, channels),\n",
        "    )\n",
        "    x = tf.transpose(x, perm=(0, 1, 3, 2, 4, 5))\n",
        "    x = tf.reshape(x, shape=(-1, height, width, channels))\n",
        "    return x\n",
        "\n",
        "\n",
        "class DropPath(layers.Layer):\n",
        "    def __init__(self, drop_prob=None, **kwargs):\n",
        "        super(DropPath, self).__init__(**kwargs)\n",
        "        self.drop_prob = drop_prob\n",
        "\n",
        "    def call(self, inputs, training=None):\n",
        "        if self.drop_prob == 0.0 or not training:\n",
        "            return inputs\n",
        "        else:\n",
        "            batch_size = tf.shape(inputs)[0]\n",
        "            keep_prob = 1 - self.drop_prob\n",
        "            path_mask_shape = (batch_size,) + (1,) * (len(tf.shape(inputs)) - 1)\n",
        "            path_mask = tf.floor(\n",
        "                backend.random_bernoulli(path_mask_shape, p=keep_prob)\n",
        "            )\n",
        "            outputs = (\n",
        "                tf.math.divide(tf.cast(inputs, dtype=tf.float32), keep_prob) * path_mask\n",
        "            )\n",
        "            return outputs\n",
        "\n",
        "    def get_config(self):\n",
        "        config = super().get_config()\n",
        "        config.update(\n",
        "            {\n",
        "                \"drop_prob\": self.drop_prob,\n",
        "            }\n",
        "        )\n",
        "        return config"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "ht6pCDkfv_Ko"
      },
      "outputs": [],
      "source": [
        "class PatchExtract(layers.Layer):\n",
        "    def __init__(self, patch_size, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.patch_size_x = patch_size[0]\n",
        "        self.patch_size_y = patch_size[0]\n",
        "\n",
        "    def call(self, images):\n",
        "        batch_size = tf.shape(images)[0]\n",
        "        patches = tf.image.extract_patches(\n",
        "            images=images,\n",
        "            sizes=(1, self.patch_size_x, self.patch_size_y, 1),\n",
        "            strides=(1, self.patch_size_x, self.patch_size_y, 1),\n",
        "            rates=(1, 1, 1, 1),\n",
        "            padding=\"VALID\",\n",
        "        )\n",
        "        patch_dim = patches.shape[-1]\n",
        "        patch_num = patches.shape[1]\n",
        "        return tf.reshape(patches, (batch_size, patch_num * patch_num, patch_dim))\n",
        "\n",
        "    def get_config(self):\n",
        "        config = super().get_config()\n",
        "        config.update(\n",
        "            {\n",
        "                \"patch_size_y\": self.patch_size_y,\n",
        "                \"patch_size_x\": self.patch_size_x,\n",
        "            }\n",
        "        )\n",
        "        return config\n",
        "\n",
        "\n",
        "class PatchEmbedding(layers.Layer):\n",
        "    def __init__(self, num_patch, embed_dim, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.num_patch = num_patch\n",
        "        self.proj = layers.Dense(embed_dim)\n",
        "        self.pos_embed = layers.Embedding(input_dim=num_patch, output_dim=embed_dim)\n",
        "\n",
        "    def call(self, patch):\n",
        "        pos = tf.range(start=0, limit=self.num_patch, delta=1)\n",
        "        return self.proj(patch) + self.pos_embed(pos)\n",
        "\n",
        "    def get_config(self):\n",
        "        config = super().get_config()\n",
        "        config.update(\n",
        "            {\n",
        "                \"num_patch\": self.num_patch,\n",
        "            }\n",
        "        )\n",
        "        return config\n",
        "\n",
        "\n",
        "class PatchMerging(layers.Layer):\n",
        "    def __init__(self, num_patch, embed_dim):\n",
        "        super().__init__()\n",
        "        self.num_patch = num_patch\n",
        "        self.embed_dim = embed_dim\n",
        "        self.linear_trans = layers.Dense(2 * embed_dim, use_bias=False)\n",
        "\n",
        "    def call(self, x):\n",
        "        height, width = self.num_patch\n",
        "        _, _, C = x.get_shape().as_list()\n",
        "        x = tf.reshape(x, shape=(-1, height, width, C))\n",
        "        feat_maps = x\n",
        "\n",
        "        x0 = x[:, 0::2, 0::2, :]\n",
        "        x1 = x[:, 1::2, 0::2, :]\n",
        "        x2 = x[:, 0::2, 1::2, :]\n",
        "        x3 = x[:, 1::2, 1::2, :]\n",
        "        x = tf.concat((x0, x1, x2, x3), axis=-1)\n",
        "        x = tf.reshape(x, shape=(-1, (height // 2) * (width // 2), 4 * C))\n",
        "        return self.linear_trans(x), feat_maps\n",
        "\n",
        "    def get_config(self):\n",
        "        config = super().get_config()\n",
        "        config.update({\"num_patch\": self.num_patch, \"embed_dim\": self.embed_dim})\n",
        "        return config"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "rgRXRZBPwDm6"
      },
      "outputs": [],
      "source": [
        "class WindowAttention(layers.Layer):\n",
        "    def __init__(\n",
        "        self,\n",
        "        dim,\n",
        "        window_size,\n",
        "        num_heads,\n",
        "        qkv_bias=True,\n",
        "        dropout_rate=0.0,\n",
        "        return_attention_scores=False,\n",
        "        **kwargs\n",
        "    ):\n",
        "        super().__init__(**kwargs)\n",
        "        self.dim = dim\n",
        "        self.window_size = window_size\n",
        "        self.num_heads = num_heads\n",
        "        self.scale = (dim // num_heads) ** -0.5\n",
        "        self.return_attention_scores = return_attention_scores\n",
        "        self.qkv = layers.Dense(dim * 3, use_bias=qkv_bias)\n",
        "        self.dropout = layers.Dropout(dropout_rate)\n",
        "        self.proj = layers.Dense(dim)\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        self.relative_position_bias_table = self.add_weight(\n",
        "            shape=(\n",
        "                (2 * self.window_size[0] - 1) * (2 * self.window_size[1] - 1),\n",
        "                self.num_heads,\n",
        "            ),\n",
        "            initializer=\"zeros\",\n",
        "            trainable=True,\n",
        "            name=\"relative_position_bias_table\",\n",
        "        )\n",
        "\n",
        "        self.relative_position_index = self.get_relative_position_index(\n",
        "            self.window_size[0], self.window_size[1]\n",
        "        )\n",
        "        super().build(input_shape)\n",
        "\n",
        "    def get_relative_position_index(self, window_height, window_width):\n",
        "        x_x, y_y = tf.meshgrid(range(window_height), range(window_width))\n",
        "        coords = tf.stack([y_y, x_x], axis=0)\n",
        "        coords_flatten = tf.reshape(coords, [2, -1])\n",
        "\n",
        "        relative_coords = coords_flatten[:, :, None] - coords_flatten[:, None, :]\n",
        "        relative_coords = tf.transpose(relative_coords, perm=[1, 2, 0])\n",
        "\n",
        "        x_x = (relative_coords[:, :, 0] + window_height - 1) * (2 * window_width - 1)\n",
        "        y_y = relative_coords[:, :, 1] + window_width - 1\n",
        "        relative_coords = tf.stack([x_x, y_y], axis=-1)\n",
        "\n",
        "        return tf.reduce_sum(relative_coords, axis=-1)\n",
        "\n",
        "    def call(self, x, mask=None):\n",
        "        _, size, channels = x.shape\n",
        "        head_dim = channels // self.num_heads\n",
        "        x_qkv = self.qkv(x)\n",
        "        x_qkv = tf.reshape(x_qkv, shape=(-1, size, 3, self.num_heads, head_dim))\n",
        "        x_qkv = tf.transpose(x_qkv, perm=(2, 0, 3, 1, 4))\n",
        "        q, k, v = x_qkv[0], x_qkv[1], x_qkv[2]\n",
        "        q = q * self.scale\n",
        "        k = tf.transpose(k, perm=(0, 1, 3, 2))\n",
        "        attn = q @ k\n",
        "\n",
        "        relative_position_bias = tf.gather(\n",
        "            self.relative_position_bias_table,\n",
        "            self.relative_position_index,\n",
        "            axis=0,\n",
        "        )\n",
        "        relative_position_bias = tf.transpose(relative_position_bias, [2, 0, 1])\n",
        "        attn = attn + tf.expand_dims(relative_position_bias, axis=0)\n",
        "\n",
        "        if mask is not None:\n",
        "            nW = mask.get_shape()[0]\n",
        "            mask_float = tf.cast(\n",
        "                tf.expand_dims(tf.expand_dims(mask, axis=1), axis=0), tf.float32\n",
        "            )\n",
        "            attn = (\n",
        "                tf.reshape(attn, shape=(-1, nW, self.num_heads, size, size))\n",
        "                + mask_float\n",
        "            )\n",
        "            attn = tf.reshape(attn, shape=(-1, self.num_heads, size, size))\n",
        "            attn = tf.nn.softmax(attn, axis=-1)\n",
        "        else:\n",
        "            attn = tf.nn.softmax(attn, axis=-1)\n",
        "        attn = self.dropout(attn)\n",
        "\n",
        "        x_qkv = attn @ v\n",
        "        x_qkv = tf.transpose(x_qkv, perm=(0, 2, 1, 3))\n",
        "        x_qkv = tf.reshape(x_qkv, shape=(-1, size, channels))\n",
        "        x_qkv = self.proj(x_qkv)\n",
        "        x_qkv = self.dropout(x_qkv)\n",
        "\n",
        "        if self.return_attention_scores:\n",
        "            return x_qkv, attn\n",
        "        else:\n",
        "            return x_qkv\n",
        "\n",
        "    def get_config(self):\n",
        "        config = super().get_config()\n",
        "        config.update(\n",
        "            {\n",
        "                \"dim\": self.dim,\n",
        "                \"window_size\": self.window_size,\n",
        "                \"num_heads\": self.num_heads,\n",
        "                \"scale\": self.scale,\n",
        "            }\n",
        "        )\n",
        "        return config"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "QeSTKb3bwI2t"
      },
      "outputs": [],
      "source": [
        "import jax\n",
        "from jax import jit\n",
        "from jax import random\n",
        "from jax import numpy as jnp\n",
        "from jax.experimental import jax2tf\n",
        "\n",
        "class SwinTransformer(layers.Layer):\n",
        "    def __init__(\n",
        "        self, \n",
        "        dim,\n",
        "        num_patch,\n",
        "        num_heads,\n",
        "        window_size=7,\n",
        "        shift_size=0,\n",
        "        num_mlp=1024,\n",
        "        qkv_bias=True,\n",
        "        dropout_rate=0.0,\n",
        "        **kwargs,\n",
        "    ):\n",
        "        super(SwinTransformer, self).__init__(**kwargs)\n",
        "\n",
        "        self.dim = dim \n",
        "        self.num_patch = num_patch  \n",
        "        self.num_heads = num_heads \n",
        "        self.window_size = window_size  \n",
        "        self.shift_size = shift_size  \n",
        "        self.num_mlp = num_mlp  \n",
        "\n",
        "        self.norm1 = layers.LayerNormalization(epsilon=1e-5)\n",
        "        self.attn = WindowAttention(\n",
        "            dim,\n",
        "            window_size=(self.window_size, self.window_size),\n",
        "            num_heads=num_heads,\n",
        "            qkv_bias=qkv_bias,\n",
        "            dropout_rate=dropout_rate,\n",
        "        )\n",
        "        self.drop_path = (\n",
        "            DropPath(dropout_rate) if dropout_rate > 0.0 else tf.identity\n",
        "        )\n",
        "        self.norm2 = layers.LayerNormalization(epsilon=1e-5)\n",
        "\n",
        "        self.mlp = keras.Sequential(\n",
        "            [\n",
        "                layers.Dense(num_mlp),\n",
        "                layers.Activation(keras.activations.gelu),\n",
        "                layers.Dropout(dropout_rate),\n",
        "                layers.Dense(dim),\n",
        "                layers.Dropout(dropout_rate),\n",
        "            ]\n",
        "        )\n",
        "\n",
        "        if min(self.num_patch) < self.window_size:\n",
        "            self.shift_size = 0\n",
        "            self.window_size = min(self.num_patch)\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        if self.shift_size == 0:\n",
        "            self.attn_mask = None\n",
        "        else:\n",
        "            height, width = self.num_patch\n",
        "            h_slices = (\n",
        "                slice(0, -self.window_size),\n",
        "                slice(-self.window_size, -self.shift_size),\n",
        "                slice(-self.shift_size, None),\n",
        "            )\n",
        "            w_slices = (\n",
        "                slice(0, -self.window_size),\n",
        "                slice(-self.window_size, -self.shift_size),\n",
        "                slice(-self.shift_size, None),\n",
        "            )\n",
        "            mask_array = jnp.zeros((1, height, width, 1))\n",
        "            count = 0\n",
        "            for h in h_slices:\n",
        "                for w in w_slices:\n",
        "                    mask_array[:, h, w, :] = count\n",
        "                    count += 1\n",
        "            mask_array = tf.convert_to_tensor(mask_array)\n",
        "\n",
        "            # mask array to windows\n",
        "            mask_windows = window_partition(mask_array, self.window_size)\n",
        "            mask_windows = tf.reshape(\n",
        "                mask_windows, shape=[-1, self.window_size * self.window_size]\n",
        "            )\n",
        "            attn_mask = tf.expand_dims(mask_windows, axis=1) - tf.expand_dims(\n",
        "                mask_windows, axis=2\n",
        "            )\n",
        "            attn_mask = tf.where(attn_mask != 0, -100.0, attn_mask)\n",
        "            attn_mask = tf.where(attn_mask == 0, 0.0, attn_mask)\n",
        "            self.attn_mask = tf.Variable(initial_value=attn_mask, trainable=False)\n",
        "\n",
        "    def call(self, x):\n",
        "        height, width = self.num_patch\n",
        "        _, num_patches_before, channels = x.shape\n",
        "        x_skip = x\n",
        "        x = self.norm1(x)\n",
        "        x = tf.reshape(x, shape=(-1, height, width, channels))\n",
        "        if self.shift_size > 0:\n",
        "            shifted_x = tf.roll(\n",
        "                x, shift=[-self.shift_size, -self.shift_size], axis=[1, 2]\n",
        "            )\n",
        "        else:\n",
        "            shifted_x = x\n",
        "\n",
        "        x_windows = window_partition(shifted_x, self.window_size)\n",
        "        x_windows = tf.reshape(\n",
        "            x_windows, shape=(-1, self.window_size * self.window_size, channels)\n",
        "        )\n",
        "        attn_windows = self.attn(x_windows, mask=self.attn_mask)\n",
        "\n",
        "        attn_windows = tf.reshape(\n",
        "            attn_windows, shape=(-1, self.window_size, self.window_size, channels)\n",
        "        )\n",
        "        shifted_x = window_reverse(\n",
        "            attn_windows, self.window_size, height, width, channels\n",
        "        )\n",
        "        if self.shift_size > 0:\n",
        "            x = tf.roll(\n",
        "                shifted_x, shift=[self.shift_size, self.shift_size], axis=[1, 2]\n",
        "            )\n",
        "        else:\n",
        "            x = shifted_x\n",
        "\n",
        "        x = tf.reshape(x, shape=(-1, height * width, channels))\n",
        "        x = self.drop_path(x)\n",
        "        x = tf.cast(x_skip, dtype=tf.float32) + tf.cast(x, dtype=tf.float32)\n",
        "        x_skip = x\n",
        "        x = self.norm2(x)\n",
        "        x = self.mlp(x)\n",
        "        x = self.drop_path(x)\n",
        "        x = tf.cast(x_skip, dtype=tf.float32) + tf.cast(x, dtype=tf.float32)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "Tj_o7vvSFBx6"
      },
      "outputs": [],
      "source": [
        "# creating a custom train_step to override the train_step method of sub_classing model\n",
        "def train_step_sam(self, data, rho=0.05):\n",
        "    \"\"\"\n",
        "    Overrides the train_step method of Model\n",
        "    \n",
        "    Args:\n",
        "        data : Data on which model is to be trained\n",
        "        rho  : Hyperparameter Rho indicating the size of neighborhood\n",
        "    \"\"\"\n",
        "    \n",
        "    sample_weight = None\n",
        "    x, y = data\n",
        "\n",
        "    # Opening Gradient Tape scope to record operations during 1st forward pass\n",
        "    with tf.GradientTape() as tape:\n",
        "        y_pred = self(x, training=True)\n",
        "        # Calculating loss to calculate gradients\n",
        "        loss = self.compiled_loss(y, y_pred, sample_weight=sample_weight, regularization_losses=self.losses)\n",
        "\n",
        "    \n",
        "    trainable_vars = self.trainable_variables\n",
        "    # Calculating gradients with respect trainable variable\n",
        "    gradients = tape.gradient(loss, trainable_vars)\n",
        "\n",
        "    \"\"\"\n",
        "    This is the first step which involves calculating the point w_adv with highest loss and virtually moving to that point so that we can get gradient at that point. \n",
        "    \"\"\"\n",
        "    eps_w_ls = [] # list to store the updates done to trainable variables in first step\n",
        "    \n",
        "    #computing the norm of gradients which is required for computing eps_w\n",
        "    grad_norm = tf.linalg.global_norm(gradients)\n",
        "    \n",
        "    # Iterating over trainable_vars\n",
        "    for i in range(len(trainable_vars)):\n",
        "        # we will calculate eps_w to find w_adv point having highest loss in rho neighborhood\n",
        "        eps_w = tf.math.multiply(gradients[i], rho / grad_norm )\n",
        "        # temporarily moving to w_adv point\n",
        "        trainable_vars[i].assign_add(eps_w)\n",
        "        # storing updates done in eps_w_ls list \n",
        "        eps_w_ls.append(eps_w)\n",
        "\n",
        "    # Opening Gradient Tape scope to record operations during 2nd forward pass\n",
        "    with tf.GradientTape() as tape:\n",
        "        y_pred = self(x, training=True) \n",
        "        # Calculating loss to calculate gradient at w_adv point\n",
        "        loss = self.compiled_loss(y, y_pred, sample_weight=sample_weight, regularization_losses=self.losses)\n",
        "        \n",
        "    trainable_vars = self.trainable_variables\n",
        "    #computing gradient at w_adv which is our objective in this first step\n",
        "    gradients = tape.gradient(loss, trainable_vars)\n",
        "\n",
        "    \"\"\"\n",
        "    This is the second step in SAM where we will do actual update at the initial point from the gradient calculated at adversial point w_adv \n",
        "    \"\"\"\n",
        "    \n",
        "    for i in range(len(trainable_vars)):\n",
        "        # Going back to orignal parameters\n",
        "        trainable_vars[i].assign_sub(eps_w_ls[i])\n",
        "    \n",
        "    # Updating parameters with gradients computed at w_adv\n",
        "    self.optimizer.apply_gradients(zip(gradients, trainable_vars))\n",
        "\n",
        "    # Updating the metrics.\n",
        "    self.compiled_metrics.update_state(y, y_pred, sample_weight=sample_weight)\n",
        "\n",
        "    # returns a dictionary mapping metric names (including the loss) to their current value.\n",
        "    return {m.name: m.result() for m in self.metrics}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "KcKD__IYQ_kM"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout, BatchNormalization, LayerNormalization\n",
        "from tensorflow.keras import regularizers\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.applications.efficientnet_v2 import EfficientNetV2M\n",
        "from sklearn.metrics import f1_score\n",
        "from tensorflow.keras.losses import categorical_crossentropy\n",
        "\n",
        "with strategy.scope():\n",
        "    base = EfficientNetV2M(weights='imagenet', include_top=False, input_shape=(img_height, img_width, 3))\n",
        "\n",
        "    class HybridModel(keras.Model):\n",
        "        def __init__(self, model_name, **kwargs):\n",
        "            super().__init__(name=model_name, **kwargs)\n",
        "\n",
        "            # base model with compatible output which will be an input of transformer model\n",
        "            self.multi_output_cnn = keras.Model(\n",
        "                [base.inputs],\n",
        "                [base.get_layer(\"block6a_expand_activation\").output, base.output],\n",
        "                name=\"efficientnet\",\n",
        "            )\n",
        "\n",
        "            # base model's (cnn model) head\n",
        "            self.conv_head = keras.Sequential(\n",
        "                [\n",
        "                    layers.GlobalAveragePooling2D(),\n",
        "                    layers.AlphaDropout(0.5),\n",
        "                    layers.LayerNormalization()\n",
        "                ],\n",
        "                name=\"conv_head\",\n",
        "            )\n",
        "\n",
        "            # stuff of swin transformers\n",
        "            self.patch_extract = PatchExtract(patch_size)\n",
        "            self.patch_embedds = PatchEmbedding(num_patch_x * num_patch_y, embed_dim)\n",
        "            self.patch_merging = PatchMerging(\n",
        "                (num_patch_x, num_patch_y), embed_dim=embed_dim\n",
        "            )\n",
        "\n",
        "            # swin blocks containers\n",
        "            self.swin_sequences = keras.Sequential(name=\"swin_blocks\")\n",
        "            for i in range(shift_size):\n",
        "                self.swin_sequences.add(\n",
        "                    SwinTransformer(\n",
        "                        dim=embed_dim,\n",
        "                        num_patch=(num_patch_x, num_patch_y),\n",
        "                        num_heads=num_heads,\n",
        "                        window_size=window_size,\n",
        "                        shift_size=i,\n",
        "                        num_mlp=num_mlp,\n",
        "                        qkv_bias=qkv_bias,\n",
        "                        dropout_rate=dropout_rate,\n",
        "                    )\n",
        "                )\n",
        "\n",
        "            # swin block's head\n",
        "            self.swin_head = keras.Sequential(\n",
        "                [\n",
        "                    layers.GlobalAveragePooling1D(),\n",
        "                    layers.AlphaDropout(0.5),\n",
        "                    layers.LayerNormalization(),\n",
        "                ],\n",
        "                name=\"swin_head\",\n",
        "            )\n",
        "\n",
        "            # classifier\n",
        "            self.classifier = layers.Dense(\n",
        "                19, activation='softmax'\n",
        "            )\n",
        "\n",
        "            # build the graph\n",
        "            self.build_graph()\n",
        "\n",
        "        def forward_cnn(self, inputs):\n",
        "            # CNN model.\n",
        "            return self.multi_output_cnn(inputs)\n",
        "\n",
        "        def forward_transformer(self, inputs):\n",
        "            # Transformer model.\n",
        "            x = self.patch_extract(inputs)\n",
        "            x = self.patch_embedds(x)\n",
        "            x = self.swin_sequences(tf.cast(x, dtype=tf.float32))\n",
        "            x, swin_gcam_top = self.patch_merging(x)\n",
        "            return x, swin_gcam_top\n",
        "\n",
        "        def call(self, inputs, training=None, **kwargs):\n",
        "            cnn_mid_layer, cnn_gcam_top = self.forward_cnn(inputs)\n",
        "            transformer_output, transformer_gcam_top = self.forward_transformer(\n",
        "                cnn_mid_layer\n",
        "            )\n",
        "\n",
        "            transformer_output = self.swin_head(transformer_output)\n",
        "            cnn_output = self.conv_head(cnn_gcam_top)\n",
        "            logits = self.classifier(tf.concat([transformer_output, cnn_output], axis=-1))\n",
        "\n",
        "            return logits\n",
        "\n",
        "        def build_graph(self):\n",
        "            x = keras.Input(shape=(img_width, img_height, 3))\n",
        "            return keras.Model(inputs=[x], outputs=self.call(x))\n",
        "        \n",
        "        # overriding the train_step method  with our custom train_step_sam created in earlier cell\n",
        "        def train_step(self, data):\n",
        "            return train_step_sam(self, data, rho=0.05) # using rho as 0.05 you can tune this hyperparameter\n",
        "\n",
        "    # focal loss 정의\n",
        "    def focal_loss(gamma=2.0, alpha=0.25):\n",
        "        def loss(y_true, y_pred):\n",
        "            ce_loss = categorical_crossentropy(y_true, y_pred)\n",
        "            pt = tf.math.exp(-ce_loss)\n",
        "            focal_loss = alpha * tf.math.pow(1. - pt, gamma) * ce_loss\n",
        "            return focal_loss\n",
        "        return loss\n",
        "\n",
        "    model = HybridModel(\"efficientnet\")\n",
        "    model.build(input_shape=(None, img_height, img_width, 3))\n",
        "\n",
        "    model.compile(\n",
        "        optimizer = tf.keras.optimizers.AdamW(learning_rate=0.0001),\n",
        "        loss = focal_loss(),\n",
        "        metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EF2KsF3bPp1X",
        "outputId": "41f1c858-e82b-4b97-aa3e-ff092ca607dc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"efficientnet\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " efficientnet (Functional)   [(None, 24, 24, 1056),    53150388  \n",
            "                              (None, 12, 12, 1280)]              \n",
            "                                                                 \n",
            " conv_head (Sequential)      (None, 1280)              2560      \n",
            "                                                                 \n",
            " patch_extract_5 (PatchExtra  (None, 144, 4224)        0         \n",
            " ct)                                                             \n",
            "                                                                 \n",
            " patch_embedding_5 (PatchEmb  (None, 144, 64)          279616    \n",
            " edding)                                                         \n",
            "                                                                 \n",
            " patch_merging_5 (PatchMergi  ((None, 36, 128),        32768     \n",
            " ng)                          (None, 12, 12, 64))                \n",
            "                                                                 \n",
            " swin_blocks (Sequential)    (None, 144, 64)           33544     \n",
            "                                                                 \n",
            " swin_head (Sequential)      (None, 128)               256       \n",
            "                                                                 \n",
            " dense_41 (Dense)            (None, 19)                26771     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 53,525,903\n",
            "Trainable params: 53,233,871\n",
            "Non-trainable params: 292,032\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DnoYfQt1SJd6",
        "outputId": "b07c2838-7abc-4776-dfe7-eb6188d5c0d6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "150/150 [==============================] - 469s 642ms/step - loss: 0.6650 - accuracy: 0.1921 - val_loss: 0.7479 - val_accuracy: 0.6217 - lr: 1.0000e-04\n",
            "Epoch 2/30\n",
            "150/150 [==============================] - 54s 357ms/step - loss: 0.4146 - accuracy: 0.4031 - val_loss: 0.6097 - val_accuracy: 0.7425 - lr: 1.0000e-04\n",
            "Epoch 3/30\n",
            "150/150 [==============================] - 54s 359ms/step - loss: 0.2756 - accuracy: 0.5648 - val_loss: 0.5164 - val_accuracy: 0.8167 - lr: 1.0000e-04\n",
            "Epoch 4/30\n",
            "150/150 [==============================] - 53s 354ms/step - loss: 0.1949 - accuracy: 0.6690 - val_loss: 0.4893 - val_accuracy: 0.8467 - lr: 1.0000e-04\n",
            "Epoch 5/30\n",
            "150/150 [==============================] - 53s 354ms/step - loss: 0.1306 - accuracy: 0.7654 - val_loss: 0.4462 - val_accuracy: 0.8650 - lr: 1.0000e-04\n",
            "Epoch 6/30\n",
            "150/150 [==============================] - 53s 351ms/step - loss: 0.1027 - accuracy: 0.8115 - val_loss: 0.4053 - val_accuracy: 0.8917 - lr: 1.0000e-04\n",
            "Epoch 7/30\n",
            "150/150 [==============================] - 49s 325ms/step - loss: 0.0783 - accuracy: 0.8479 - val_loss: 0.5004 - val_accuracy: 0.8667 - lr: 1.0000e-04\n",
            "Epoch 8/30\n",
            "150/150 [==============================] - 50s 330ms/step - loss: 0.0678 - accuracy: 0.8594 - val_loss: 0.4197 - val_accuracy: 0.8917 - lr: 1.0000e-04\n",
            "Epoch 9/30\n",
            "150/150 [==============================] - 54s 358ms/step - loss: 0.0575 - accuracy: 0.8902 - val_loss: 0.3492 - val_accuracy: 0.9017 - lr: 1.0000e-04\n",
            "Epoch 10/30\n",
            "150/150 [==============================] - 50s 330ms/step - loss: 0.0459 - accuracy: 0.9090 - val_loss: 0.3525 - val_accuracy: 0.9117 - lr: 1.0000e-04\n",
            "Epoch 11/30\n",
            "150/150 [==============================] - 49s 330ms/step - loss: 0.0393 - accuracy: 0.9198 - val_loss: 0.3821 - val_accuracy: 0.9067 - lr: 1.0000e-04\n",
            "Epoch 12/30\n",
            "150/150 [==============================] - 49s 329ms/step - loss: 0.0332 - accuracy: 0.9310 - val_loss: 0.3998 - val_accuracy: 0.9050 - lr: 1.0000e-04\n",
            "Epoch 13/30\n",
            "150/150 [==============================] - 53s 357ms/step - loss: 0.0285 - accuracy: 0.9406 - val_loss: 0.3148 - val_accuracy: 0.9117 - lr: 1.0000e-04\n",
            "Epoch 14/30\n",
            "150/150 [==============================] - 49s 326ms/step - loss: 0.0283 - accuracy: 0.9423 - val_loss: 0.3663 - val_accuracy: 0.9208 - lr: 1.0000e-04\n",
            "Epoch 15/30\n",
            "150/150 [==============================] - 49s 324ms/step - loss: 0.0261 - accuracy: 0.9448 - val_loss: 0.4567 - val_accuracy: 0.9042 - lr: 1.0000e-04\n",
            "Epoch 16/30\n",
            "150/150 [==============================] - 48s 323ms/step - loss: 0.0234 - accuracy: 0.9500 - val_loss: 0.3845 - val_accuracy: 0.9158 - lr: 1.0000e-04\n",
            "Epoch 17/30\n",
            "150/150 [==============================] - 49s 327ms/step - loss: 0.0229 - accuracy: 0.9533 - val_loss: 0.4060 - val_accuracy: 0.9067 - lr: 1.0000e-04\n",
            "Epoch 18/30\n",
            "150/150 [==============================] - 49s 324ms/step - loss: 0.0235 - accuracy: 0.9506 - val_loss: 0.3472 - val_accuracy: 0.9133 - lr: 1.0000e-04\n",
            "Epoch 19/30\n",
            "150/150 [==============================] - 53s 354ms/step - loss: 0.0149 - accuracy: 0.9652 - val_loss: 0.2968 - val_accuracy: 0.9308 - lr: 1.0000e-05\n",
            "Epoch 20/30\n",
            "150/150 [==============================] - 48s 322ms/step - loss: 0.0115 - accuracy: 0.9758 - val_loss: 0.3035 - val_accuracy: 0.9275 - lr: 1.0000e-05\n",
            "Epoch 21/30\n",
            "150/150 [==============================] - 48s 323ms/step - loss: 0.0099 - accuracy: 0.9806 - val_loss: 0.3236 - val_accuracy: 0.9258 - lr: 1.0000e-05\n",
            "Epoch 22/30\n",
            "150/150 [==============================] - 49s 325ms/step - loss: 0.0094 - accuracy: 0.9787 - val_loss: 0.3391 - val_accuracy: 0.9283 - lr: 1.0000e-05\n",
            "Epoch 23/30\n",
            "150/150 [==============================] - 48s 323ms/step - loss: 0.0088 - accuracy: 0.9815 - val_loss: 0.3243 - val_accuracy: 0.9300 - lr: 1.0000e-05\n",
            "Epoch 24/30\n",
            "150/150 [==============================] - 48s 323ms/step - loss: 0.0093 - accuracy: 0.9806 - val_loss: 0.3385 - val_accuracy: 0.9217 - lr: 1.0000e-05\n",
            "Epoch 25/30\n",
            "150/150 [==============================] - 48s 322ms/step - loss: 0.0074 - accuracy: 0.9844 - val_loss: 0.3313 - val_accuracy: 0.9283 - lr: 1.0000e-06\n",
            "Epoch 26/30\n",
            "150/150 [==============================] - 48s 321ms/step - loss: 0.0084 - accuracy: 0.9854 - val_loss: 0.3418 - val_accuracy: 0.9233 - lr: 1.0000e-06\n",
            "Epoch 27/30\n",
            "150/150 [==============================] - 70s 467ms/step - loss: 0.0075 - accuracy: 0.9875 - val_loss: 0.3376 - val_accuracy: 0.9283 - lr: 1.0000e-06\n",
            "38/38 [==============================] - 34s 752ms/step\n",
            "Fold 1 - f1_score: 0.9302283066585367\n",
            "Epoch 1/30\n",
            "150/150 [==============================] - 63s 422ms/step - loss: 0.0376 - accuracy: 0.9425 - val_loss: 1.7672e-04 - val_accuracy: 0.9992 - lr: 1.0000e-06\n",
            "Epoch 2/30\n",
            "150/150 [==============================] - 49s 325ms/step - loss: 0.0381 - accuracy: 0.9419 - val_loss: 0.0028 - val_accuracy: 0.9983 - lr: 1.0000e-06\n",
            "Epoch 3/30\n",
            "150/150 [==============================] - 49s 326ms/step - loss: 0.0356 - accuracy: 0.9435 - val_loss: 0.0035 - val_accuracy: 0.9983 - lr: 1.0000e-06\n",
            "Epoch 4/30\n",
            "150/150 [==============================] - 49s 327ms/step - loss: 0.0327 - accuracy: 0.9435 - val_loss: 0.0038 - val_accuracy: 0.9967 - lr: 1.0000e-06\n",
            "Epoch 5/30\n",
            "150/150 [==============================] - 49s 326ms/step - loss: 0.0349 - accuracy: 0.9406 - val_loss: 0.0064 - val_accuracy: 0.9967 - lr: 1.0000e-06\n",
            "Epoch 6/30\n",
            "150/150 [==============================] - 49s 325ms/step - loss: 0.0319 - accuracy: 0.9465 - val_loss: 0.0013 - val_accuracy: 0.9975 - lr: 1.0000e-06\n",
            "Epoch 7/30\n",
            "150/150 [==============================] - 49s 326ms/step - loss: 0.0311 - accuracy: 0.9492 - val_loss: 0.0014 - val_accuracy: 0.9992 - lr: 1.0000e-07\n",
            "Epoch 8/30\n",
            "150/150 [==============================] - 49s 326ms/step - loss: 0.0321 - accuracy: 0.9467 - val_loss: 0.0016 - val_accuracy: 0.9975 - lr: 1.0000e-07\n",
            "Epoch 9/30\n",
            "150/150 [==============================] - 70s 466ms/step - loss: 0.0341 - accuracy: 0.9452 - val_loss: 0.0060 - val_accuracy: 0.9975 - lr: 1.0000e-07\n",
            "38/38 [==============================] - 3s 56ms/step\n",
            "Fold 2 - f1_score: 0.9983375282394519\n",
            "Epoch 1/30\n",
            "150/150 [==============================] - 62s 415ms/step - loss: 0.0336 - accuracy: 0.9444 - val_loss: 4.7861e-04 - val_accuracy: 0.9992 - lr: 1.0000e-07\n",
            "Epoch 2/30\n",
            "150/150 [==============================] - 48s 322ms/step - loss: 0.0336 - accuracy: 0.9458 - val_loss: 0.0042 - val_accuracy: 0.9975 - lr: 1.0000e-07\n",
            "Epoch 3/30\n",
            "150/150 [==============================] - 49s 324ms/step - loss: 0.0371 - accuracy: 0.9408 - val_loss: 0.0057 - val_accuracy: 0.9992 - lr: 1.0000e-07\n",
            "Epoch 4/30\n",
            "150/150 [==============================] - 49s 325ms/step - loss: 0.0347 - accuracy: 0.9423 - val_loss: 0.0016 - val_accuracy: 0.9992 - lr: 1.0000e-07\n",
            "Epoch 5/30\n",
            "150/150 [==============================] - 49s 327ms/step - loss: 0.0362 - accuracy: 0.9402 - val_loss: 1.8874e-08 - val_accuracy: 1.0000 - lr: 1.0000e-07\n",
            "Epoch 6/30\n",
            "150/150 [==============================] - 49s 324ms/step - loss: 0.0376 - accuracy: 0.9375 - val_loss: 0.0043 - val_accuracy: 0.9992 - lr: 1.0000e-07\n",
            "Epoch 7/30\n",
            "150/150 [==============================] - 49s 325ms/step - loss: 0.0353 - accuracy: 0.9458 - val_loss: 0.0027 - val_accuracy: 0.9992 - lr: 1.0000e-07\n",
            "Epoch 8/30\n",
            "150/150 [==============================] - 49s 324ms/step - loss: 0.0354 - accuracy: 0.9392 - val_loss: 4.5495e-06 - val_accuracy: 1.0000 - lr: 1.0000e-07\n",
            "Epoch 9/30\n",
            "150/150 [==============================] - 69s 463ms/step - loss: 0.0351 - accuracy: 0.9423 - val_loss: 1.9262e-04 - val_accuracy: 0.9992 - lr: 1.0000e-07\n",
            "38/38 [==============================] - 3s 57ms/step\n",
            "Fold 3 - f1_score: 1.0\n",
            "Epoch 1/30\n",
            "150/150 [==============================] - 63s 420ms/step - loss: 0.0376 - accuracy: 0.9410 - val_loss: 0.0013 - val_accuracy: 0.9992 - lr: 1.0000e-07\n",
            "Epoch 2/30\n",
            "150/150 [==============================] - 49s 329ms/step - loss: 0.0357 - accuracy: 0.9427 - val_loss: 0.0012 - val_accuracy: 0.9992 - lr: 1.0000e-07\n",
            "Epoch 3/30\n",
            "150/150 [==============================] - 53s 352ms/step - loss: 0.0362 - accuracy: 0.9373 - val_loss: 5.2191e-06 - val_accuracy: 1.0000 - lr: 1.0000e-07\n",
            "Epoch 4/30\n",
            "150/150 [==============================] - 49s 325ms/step - loss: 0.0356 - accuracy: 0.9419 - val_loss: 0.0011 - val_accuracy: 0.9992 - lr: 1.0000e-07\n",
            "Epoch 5/30\n",
            "150/150 [==============================] - 49s 326ms/step - loss: 0.0372 - accuracy: 0.9404 - val_loss: 2.2240e-04 - val_accuracy: 0.9992 - lr: 1.0000e-07\n",
            "Epoch 6/30\n",
            "150/150 [==============================] - 49s 326ms/step - loss: 0.0363 - accuracy: 0.9460 - val_loss: 7.2988e-04 - val_accuracy: 0.9983 - lr: 1.0000e-07\n",
            "Epoch 7/30\n",
            "150/150 [==============================] - 49s 324ms/step - loss: 0.0361 - accuracy: 0.9400 - val_loss: 2.3122e-05 - val_accuracy: 1.0000 - lr: 1.0000e-07\n",
            "Epoch 8/30\n",
            "150/150 [==============================] - 49s 324ms/step - loss: 0.0374 - accuracy: 0.9400 - val_loss: 5.0934e-04 - val_accuracy: 0.9992 - lr: 1.0000e-07\n",
            "Epoch 9/30\n",
            "150/150 [==============================] - 48s 323ms/step - loss: 0.0363 - accuracy: 0.9433 - val_loss: 0.0021 - val_accuracy: 0.9983 - lr: 1.0000e-08\n",
            "Epoch 10/30\n",
            "150/150 [==============================] - 48s 323ms/step - loss: 0.0338 - accuracy: 0.9433 - val_loss: 9.6771e-06 - val_accuracy: 1.0000 - lr: 1.0000e-08\n",
            "Epoch 11/30\n",
            "150/150 [==============================] - 70s 470ms/step - loss: 0.0355 - accuracy: 0.9417 - val_loss: 1.5105e-04 - val_accuracy: 0.9992 - lr: 1.0000e-08\n",
            "38/38 [==============================] - 3s 57ms/step\n",
            "Fold 4 - f1_score: 1.0\n",
            "Epoch 1/30\n",
            "150/150 [==============================] - 63s 419ms/step - loss: 0.0369 - accuracy: 0.9392 - val_loss: 0.0060 - val_accuracy: 0.9975 - lr: 1.0000e-08\n",
            "Epoch 2/30\n",
            "150/150 [==============================] - 53s 353ms/step - loss: 0.0380 - accuracy: 0.9342 - val_loss: 0.0022 - val_accuracy: 0.9992 - lr: 1.0000e-08\n",
            "Epoch 3/30\n",
            "150/150 [==============================] - 53s 354ms/step - loss: 0.0359 - accuracy: 0.9408 - val_loss: 6.2112e-04 - val_accuracy: 0.9992 - lr: 1.0000e-08\n",
            "Epoch 4/30\n",
            "150/150 [==============================] - 49s 324ms/step - loss: 0.0356 - accuracy: 0.9410 - val_loss: 0.0036 - val_accuracy: 0.9992 - lr: 1.0000e-08\n",
            "Epoch 5/30\n",
            "150/150 [==============================] - 49s 324ms/step - loss: 0.0359 - accuracy: 0.9400 - val_loss: 0.0022 - val_accuracy: 0.9983 - lr: 1.0000e-08\n",
            "Epoch 6/30\n",
            "150/150 [==============================] - 49s 324ms/step - loss: 0.0377 - accuracy: 0.9417 - val_loss: 2.4730e-04 - val_accuracy: 0.9992 - lr: 1.0000e-08\n",
            "Epoch 7/30\n",
            "150/150 [==============================] - 48s 322ms/step - loss: 0.0371 - accuracy: 0.9383 - val_loss: 0.0024 - val_accuracy: 0.9992 - lr: 1.0000e-08\n",
            "Epoch 8/30\n",
            "150/150 [==============================] - 49s 325ms/step - loss: 0.0382 - accuracy: 0.9410 - val_loss: 7.5587e-04 - val_accuracy: 0.9992 - lr: 1.0000e-08\n",
            "Epoch 9/30\n",
            "150/150 [==============================] - 49s 329ms/step - loss: 0.0356 - accuracy: 0.9463 - val_loss: 0.0012 - val_accuracy: 0.9967 - lr: 1.0000e-08\n",
            "Epoch 10/30\n",
            "150/150 [==============================] - 49s 325ms/step - loss: 0.0364 - accuracy: 0.9415 - val_loss: 0.0019 - val_accuracy: 0.9983 - lr: 1.0000e-08\n",
            "Epoch 11/30\n",
            "150/150 [==============================] - 70s 470ms/step - loss: 0.0367 - accuracy: 0.9429 - val_loss: 1.0810e-04 - val_accuracy: 0.9992 - lr: 1.0000e-08\n",
            "38/38 [==============================] - 3s 56ms/step\n",
            "Fold 5 - f1_score: 1.0\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import StratifiedKFold\n",
        "\n",
        "# 콜백들\n",
        "earlystopping = tf.keras.callbacks.EarlyStopping(\n",
        "    monitor='val_loss',\n",
        "    mode='min',\n",
        "    min_delta = 0.001,\n",
        "    patience=8,\n",
        "    restore_best_weights=True,\n",
        "    verbose=0)\n",
        "\n",
        "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=5)\n",
        "\n",
        "kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "checkpoint_dir = f'gs://hoon_bari/Dacon_wallpaper/Training model'\n",
        "best_f1_score = 0\n",
        "best_weights = None\n",
        "\n",
        "for fold, (train_index, val_index) in enumerate(kfold.split(x_data, y_encoded)):\n",
        "    \n",
        "    # 학습 데이터와 검증 데이터를 나누기\n",
        "    x_train, y_train = x_data[train_index], y_encoded[train_index]\n",
        "    x_val, y_val = x_data[val_index], y_encoded[val_index]\n",
        "\n",
        "    model.fit(x_train, tf.keras.utils.to_categorical(y_train), \n",
        "                batch_size=32, \n",
        "                epochs=30,\n",
        "                validation_data=(x_val, tf.keras.utils.to_categorical(y_val)),\n",
        "                callbacks=[earlystopping, reduce_lr])\n",
        "\n",
        "    # 모델 예측\n",
        "    y_pred = model.predict(x_val)\n",
        "    y_pred_label = np.argmax(y_pred, axis=1)\n",
        "\n",
        "    # 모델 평가\n",
        "    score_f1 = f1_score(y_val, y_pred_label, average='weighted')\n",
        "    print(f'Fold {fold+1} - f1_score:', score_f1)\n",
        "\n",
        "    # 가장 좋은 f1_score를 보인 모델 저장\n",
        "    if score_f1 > best_f1_score:\n",
        "        best_f1_score = score_f1\n",
        "        best_weights = model.get_weights()\n",
        "\n",
        "# 모델 checkpoint 저장\n",
        "checkpoint_name = f'{checkpoint_dir}/'\n",
        "model.set_weights(best_weights)\n",
        "model.save_weights(checkpoint_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bzRwzohjmcVy",
        "outputId": "75c3ef83-8aa6-4572-dc40-f5051ad02cb4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "132/132 [==============================] - 8s 55ms/step\n",
            "Train Set 평가 결과\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      1.00      1.00       105\n",
            "           1       1.00      1.00      1.00       350\n",
            "           2       0.98      1.00      0.99       210\n",
            "           3       1.00      0.99      0.99       280\n",
            "           4       1.00      1.00      1.00        70\n",
            "           5       0.98      0.99      0.99       140\n",
            "           6       0.99      0.97      0.98       210\n",
            "           7       0.98      1.00      0.99       210\n",
            "           8       0.99      1.00      0.99        70\n",
            "           9       1.00      0.99      1.00       210\n",
            "          10       0.97      0.97      0.97       490\n",
            "          11       1.00      0.99      0.99       210\n",
            "          12       0.95      1.00      0.97       140\n",
            "          13       0.96      1.00      0.98       105\n",
            "          14       0.99      1.00      1.00       140\n",
            "          15       0.99      0.98      0.99       245\n",
            "          16       1.00      1.00      1.00       105\n",
            "          17       0.99      0.99      0.99       140\n",
            "          18       0.98      0.96      0.97       770\n",
            "\n",
            "    accuracy                           0.98      4200\n",
            "   macro avg       0.99      0.99      0.99      4200\n",
            "weighted avg       0.98      0.98      0.98      4200\n",
            "\n",
            "57/57 [==============================] - 4s 55ms/step\n",
            "Validation Set 평가 결과\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      1.00      0.99        45\n",
            "           1       1.00      0.99      1.00       150\n",
            "           2       0.98      1.00      0.99        90\n",
            "           3       1.00      0.99      1.00       120\n",
            "           4       1.00      1.00      1.00        30\n",
            "           5       1.00      1.00      1.00        60\n",
            "           6       0.98      0.98      0.98        90\n",
            "           7       0.99      0.99      0.99        90\n",
            "           8       1.00      1.00      1.00        30\n",
            "           9       1.00      0.99      0.99        90\n",
            "          10       0.99      0.97      0.98       210\n",
            "          11       0.99      1.00      0.99        90\n",
            "          12       0.98      1.00      0.99        60\n",
            "          13       1.00      1.00      1.00        45\n",
            "          14       0.97      1.00      0.98        60\n",
            "          15       1.00      0.98      0.99       105\n",
            "          16       1.00      1.00      1.00        45\n",
            "          17       0.97      1.00      0.98        60\n",
            "          18       0.98      0.98      0.98       330\n",
            "\n",
            "    accuracy                           0.99      1800\n",
            "   macro avg       0.99      0.99      0.99      1800\n",
            "weighted avg       0.99      0.99      0.99      1800\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "x_train, x_val, y_train, y_val = train_test_split(x_data, y_encoded, test_size=0.3, shuffle=True, stratify=y_encoded, random_state=42)\n",
        "\n",
        "# train set 예측\n",
        "train_pred = model.predict(x_train)\n",
        "train_pred_classes = np.argmax(train_pred, axis=1)\n",
        "\n",
        "# train set 평가\n",
        "print(\"Train Set 평가 결과\")\n",
        "print(classification_report(y_train, train_pred_classes))\n",
        "\n",
        "# validation set 예측\n",
        "val_pred = model.predict(x_val)\n",
        "val_pred_classes = np.argmax(val_pred, axis=1)\n",
        "\n",
        "# validation set 평가\n",
        "print(\"Validation Set 평가 결과\")\n",
        "print(classification_report(y_val, val_pred_classes))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "4JYv9hhU-R6n"
      },
      "outputs": [],
      "source": [
        "df = pd.DataFrame(index=range(0, 0), columns=['id', 'label'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "ZF3UazRF-Ek2"
      },
      "outputs": [],
      "source": [
        "test_csv = pd.read_csv('/content/drive/MyDrive/Dacon_wallpaper/test.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "kFRTyBg0-R28",
        "outputId": "eb81c0cb-3dba-4a2c-d8d2-9d78b9f26c40"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-fd5730a6-2287-4751-b376-dc4b75d02ebe\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>img_path</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>TEST_000</td>\n",
              "      <td>./test/000.png</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>TEST_001</td>\n",
              "      <td>./test/001.png</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>TEST_002</td>\n",
              "      <td>./test/002.png</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>TEST_003</td>\n",
              "      <td>./test/003.png</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>TEST_004</td>\n",
              "      <td>./test/004.png</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>787</th>\n",
              "      <td>TEST_787</td>\n",
              "      <td>./test/787.png</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>788</th>\n",
              "      <td>TEST_788</td>\n",
              "      <td>./test/788.png</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>789</th>\n",
              "      <td>TEST_789</td>\n",
              "      <td>./test/789.png</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>790</th>\n",
              "      <td>TEST_790</td>\n",
              "      <td>./test/790.png</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>791</th>\n",
              "      <td>TEST_791</td>\n",
              "      <td>./test/791.png</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>792 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-fd5730a6-2287-4751-b376-dc4b75d02ebe')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-fd5730a6-2287-4751-b376-dc4b75d02ebe button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-fd5730a6-2287-4751-b376-dc4b75d02ebe');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "           id        img_path\n",
              "0    TEST_000  ./test/000.png\n",
              "1    TEST_001  ./test/001.png\n",
              "2    TEST_002  ./test/002.png\n",
              "3    TEST_003  ./test/003.png\n",
              "4    TEST_004  ./test/004.png\n",
              "..        ...             ...\n",
              "787  TEST_787  ./test/787.png\n",
              "788  TEST_788  ./test/788.png\n",
              "789  TEST_789  ./test/789.png\n",
              "790  TEST_790  ./test/790.png\n",
              "791  TEST_791  ./test/791.png\n",
              "\n",
              "[792 rows x 2 columns]"
            ]
          },
          "execution_count": 47,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_csv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uXqzyXk5_lGj",
        "outputId": "f5d17d10-0892-49d8-8b82-be7410131f51"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/Dacon_wallpaper\n"
          ]
        }
      ],
      "source": [
        "%cd /content/drive/MyDrive/Dacon_wallpaper"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jRxkVYIRgiR8",
        "outputId": "6588b478-4618-4842-9253-75e94bc9563b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 792/792 [00:11<00:00, 66.98it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "25/25 [==============================] - 14s 562ms/step\n"
          ]
        }
      ],
      "source": [
        "# 클래스 라벨\n",
        "class_names = ['가구수정', '걸레받이수정', '곰팡이', '꼬임', '녹오염', '들뜸', '면불량', '몰딩수정', '반점', '석고수정', '오염', '오타공', '울음', '이음부불량', '창틀,문틀수정', '터짐', '틈새과다', '피스', '훼손']\n",
        "\n",
        "# 이미지 파일 불러오기\n",
        "test_paths = test_csv['img_path'].values\n",
        "test_images = load_dataset(test_paths, img_width, img_height)\n",
        "\n",
        "# 모델 예측\n",
        "predictions = model.predict(test_images)\n",
        "\n",
        "# 예측 결과 데이터프레임에 저장\n",
        "predicted_labels = [class_names[i] for i in np.argmax(predictions, axis=1)]\n",
        "test_csv['label'] = predicted_labels\n",
        "df = test_csv[['id', 'label']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "qgjcCk4b4wec",
        "outputId": "93250e59-b09f-4070-ced1-d1b97e525447"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-2c83267e-6c61-4ef9-a079-d36378f528ca\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>TEST_000</td>\n",
              "      <td>훼손</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>TEST_001</td>\n",
              "      <td>오염</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>TEST_002</td>\n",
              "      <td>훼손</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>TEST_003</td>\n",
              "      <td>몰딩수정</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>TEST_004</td>\n",
              "      <td>오염</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>787</th>\n",
              "      <td>TEST_787</td>\n",
              "      <td>오염</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>788</th>\n",
              "      <td>TEST_788</td>\n",
              "      <td>오염</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>789</th>\n",
              "      <td>TEST_789</td>\n",
              "      <td>오염</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>790</th>\n",
              "      <td>TEST_790</td>\n",
              "      <td>오염</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>791</th>\n",
              "      <td>TEST_791</td>\n",
              "      <td>몰딩수정</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>792 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2c83267e-6c61-4ef9-a079-d36378f528ca')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-2c83267e-6c61-4ef9-a079-d36378f528ca button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-2c83267e-6c61-4ef9-a079-d36378f528ca');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "           id label\n",
              "0    TEST_000    훼손\n",
              "1    TEST_001    오염\n",
              "2    TEST_002    훼손\n",
              "3    TEST_003  몰딩수정\n",
              "4    TEST_004    오염\n",
              "..        ...   ...\n",
              "787  TEST_787    오염\n",
              "788  TEST_788    오염\n",
              "789  TEST_789    오염\n",
              "790  TEST_790    오염\n",
              "791  TEST_791  몰딩수정\n",
              "\n",
              "[792 rows x 2 columns]"
            ]
          },
          "execution_count": 54,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w7MUbdvpJH90",
        "outputId": "68043190-bbc3-41fa-9001-460d28e6d42d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "19"
            ]
          },
          "execution_count": 55,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df['label'].nunique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KN1kqBMFKwCp",
        "outputId": "599f9d22-4f2f-4843-c89f-c5c656b8411e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "훼손         321\n",
              "오염         229\n",
              "꼬임          29\n",
              "면불량         28\n",
              "터짐          23\n",
              "울음          22\n",
              "몰딩수정        21\n",
              "곰팡이         18\n",
              "오타공         18\n",
              "이음부불량       16\n",
              "피스          13\n",
              "걸레받이수정      11\n",
              "창틀,문틀수정     10\n",
              "가구수정         9\n",
              "석고수정         8\n",
              "들뜸           6\n",
              "반점           4\n",
              "녹오염          4\n",
              "틈새과다         2\n",
              "Name: label, dtype: int64"
            ]
          },
          "execution_count": 56,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df['label'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "ODRPV4vuzqp1"
      },
      "outputs": [],
      "source": [
        "# DataFrame을 csv 파일로 저장\n",
        "df.to_csv('submission.csv', index=False)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "gpuType": "V100",
      "machine_shape": "hm",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
