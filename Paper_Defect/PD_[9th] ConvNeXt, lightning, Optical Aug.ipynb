{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DIR structure\n",
    "* ./ensemble(Avg).py\n",
    "* ./exec_KFold.py\n",
    "* ./inference.py\n",
    "* ./lightning.py\n",
    "* ./stratifiedKfold_pl_data.py\n",
    "* ./runner.py\n",
    "* ./model/models.py\n",
    "* ./lightning_logs/*\n",
    "* ./prediction/*.csv\n",
    "* ./data/DATA\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ensemble(Avg).py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ./ensemble(Avg).py\n",
    "import glob\n",
    "import pandas as pd\n",
    "\n",
    "from easydict import EasyDict\n",
    "from sklearn import preprocessing\n",
    "from tqdm import tqdm\n",
    "\n",
    "from data_loader import *\n",
    "from lightning import LightningRunner\n",
    "import albumentations as A\n",
    "from albumentations.pytorch.transforms import ToTensorV2\n",
    "\n",
    "from model.models import BaseModel\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "args = EasyDict()\n",
    "\n",
    "args.img_size = 544\n",
    "args.batch_size = 4\n",
    "\n",
    "\n",
    "test_transform = A.Compose([\n",
    "                            A.Resize(args.img_size,args.img_size),\n",
    "                            A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225), max_pixel_value=255.0, always_apply=False, p=1.0),\n",
    "                            ToTensorV2()\n",
    "                            ])\n",
    "\n",
    "le = preprocessing.LabelEncoder()\n",
    "\n",
    "all_img_list = glob.glob('./data/train/*/*')\n",
    "df = pd.DataFrame(columns=['img_path', 'label'])\n",
    "df['img_path'] = all_img_list\n",
    "df['label'] = df['img_path'].apply(lambda x : str(x).split('/')[-2])\n",
    "df['label'] = le.fit_transform(df['label'])\n",
    "\n",
    "test = pd.read_csv('/root/Competitions/DACON/Papering_clf/data/test.csv')\n",
    "path = test['img_path'].values\n",
    "path = [f'/root/Competitions/DACON/Papering_clf/data/test/{file.split(\"/\")[-1]}' for file in path]\n",
    "\n",
    "\n",
    "test_dataset = CustomDataset(path, None, test_transform)\n",
    "test_loader = DataLoader(test_dataset, batch_size=args.batch_size, shuffle=False, num_workers=0)\n",
    "\n",
    "CV_path = '/root/Competitions/DACON/Papering_clf/lightning_logs/2023-05-20'\n",
    "ckpts = glob.glob(f'{CV_path}/*/checkpoints/*')\n",
    "\n",
    "inferences = []\n",
    "DEVICE = 'cuda:0'\n",
    "\n",
    "for ckpt in ckpts:\n",
    "    model = BaseModel(19).to(DEVICE)\n",
    "    pl_runner = LightningRunner.load_from_checkpoint(ckpt, network=model, args=args).to(DEVICE)\n",
    "    # pl_runner\n",
    "    pl_runner.eval()\n",
    "\n",
    "    inference  = []\n",
    "    for x in tqdm(test_loader):\n",
    "        x = x.to(DEVICE)\n",
    "\n",
    "        pred = pl_runner.model(x)\n",
    "        inference += pred.detach().cpu().numpy().tolist()\n",
    "\n",
    "        del x \n",
    "    \n",
    "    inferences.append(inference)\n",
    "\n",
    "inferences = np.mean(np.array(inferences), axis=0)\n",
    "inferences = np.argmax(inferences, axis=1)\n",
    "\n",
    "inferences = le.inverse_transform(inferences)\n",
    "submit = pd.read_csv('/root/Competitions/DACON/Papering_clf/data/sample_submission.csv')\n",
    "submit['label'] = inferences\n",
    "submit.to_csv('/root/Competitions/DACON/Papering_clf/prediction/5fold_convNeXt-Large_aug-realP-p544.csv', index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### exec_KFold.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exec_KFold.py \n",
    "from datetime import datetime, timezone, timedelta\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    from easydict import EasyDict\n",
    "    from lightning_fabric.utilities.seed import seed_everything\n",
    "    from pytorch_lightning import Trainer\n",
    "    from pytorch_lightning.strategies.ddp import DDPStrategy\n",
    "    from pytorch_lightning.callbacks import ModelCheckpoint, LearningRateMonitor, LearningRateFinder\n",
    "    from pytorch_lightning.loggers.tensorboard import TensorBoardLogger\n",
    "\n",
    "    import albumentations as A\n",
    "    from albumentations.pytorch.transforms import ToTensorV2\n",
    "\n",
    "    from lightning import LightningRunner\n",
    "    from data_loader import *\n",
    "    from model.models import *\n",
    "    from stratifiedKfold_pl_data import KFold_pl_DataModule\n",
    "\n",
    "\n",
    "\n",
    "    args = EasyDict()\n",
    "\n",
    "    args.img_size = 512\n",
    "    args.val_img_size = 544 \n",
    "\n",
    "    args.batch_size = 16\n",
    "    args.epochs = 80\n",
    "    args.init_lr = 4e-5\n",
    "    args.weight_decay = 0.05\n",
    "    args.seed = 41\n",
    "    \n",
    "\n",
    "    seed_everything(args.seed)\n",
    "    \n",
    "    \n",
    "    train_transform_4_origin = A.Compose([\n",
    "                            A.Resize(args.img_size,args.img_size),\n",
    "                            A.AdvancedBlur(),\n",
    "                            A.ColorJitter(),\n",
    "                            A.GaussNoise(),\n",
    "                            A.OpticalDistortion(distort_limit=(-0.3, 0.3), shift_limit=0.5, p=0.5),\n",
    "                            A.HorizontalFlip(),\n",
    "                            A.Affine(scale=(0.9, 2), translate_percent=(-0.1, 0.1), rotate=(-10, 10), shear=(-20,20)),\n",
    "                            A.ElasticTransform(alpha=300),\n",
    "                            A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225), max_pixel_value=255.0, always_apply=False, p=1.0),\n",
    "                            ToTensorV2()\n",
    "                            ])\n",
    "    \n",
    "    test_transform = A.Compose([\n",
    "                            A.Resize(args.val_img_size, args.val_img_size),\n",
    "                            A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225), max_pixel_value=255.0, always_apply=False, p=1.0),\n",
    "                            ToTensorV2()\n",
    "                            ])\n",
    "    \n",
    "    num_split = 5 \n",
    "    KST = timezone(timedelta(hours=9))\n",
    "    start = datetime.now(KST)\n",
    "    _day = str(start)[:10]\n",
    "    for k_idx in range(num_split):\n",
    "        pl_dataFolder = KFold_pl_DataModule(data_dir='./proc_data/train/*/*',\n",
    "                            k_idx=k_idx,\n",
    "                            num_split=num_split,\n",
    "                            split_seed=args.seed,\n",
    "                            batch_size=args.batch_size,\n",
    "                            num_workers=4,\n",
    "                            pin_memory=False,\n",
    "                            persistent_workers=True,\n",
    "                            train_transform=train_transform_4_origin,\n",
    "                            val_transform=test_transform)\n",
    "\n",
    "        pl_dataFolder.setup(stage=None)\n",
    "        model = BaseModel(pl_dataFolder.num_cls)\n",
    "        pl_runner = LightningRunner(model, args)\n",
    "        lr_monitor = LearningRateMonitor(logging_interval='step')\n",
    "        \n",
    "        checkpoint_callback = ModelCheckpoint(\n",
    "            monitor='avg_f1',\n",
    "            filename=f'{model.__class__.__name__}'+'-{epoch:03d}-{train_loss:.4f}-{avg_f1:.4f}',\n",
    "            mode='max'\n",
    "        )\n",
    "\n",
    "        logger = TensorBoardLogger(\n",
    "            save_dir='.',\n",
    "            # version='LEARNING CHECK',\n",
    "            version=f'{_day}/[{k_idx+1} Fold] -m convnext_large, -d realP, -t GV -opt AdamP || lr=[{args.init_lr}] img=[{args.img_size}] bz=[{args.batch_size}] 2gpu'\n",
    "            )\n",
    "\n",
    "        trainer = Trainer(\n",
    "            max_epochs=args.epochs,\n",
    "            devices=[2,3],\n",
    "            accelerator='gpu',\n",
    "            precision='16-mixed',\n",
    "            # strategy=DDPStrategy(find_unused_parameters=False),\n",
    "            callbacks=[lr_monitor, checkpoint_callback],\n",
    "            # check_val_every_n_epoch=2,\n",
    "            check_val_every_n_epoch=2,\n",
    "            # log_every_n_steps=1,\n",
    "            logger=logger,\n",
    "            # auto_lr_find=True\n",
    "            # accumulate_grad_batches=2\n",
    "            )\n",
    "\n",
    "        trainer.fit(\n",
    "            model= pl_runner,\n",
    "            # train_dataloaders=train_loader,\n",
    "            # val_dataloaders=val_loader\n",
    "            datamodule=pl_dataFolder\n",
    "        )\n",
    "\n",
    "    # fold iteration END\n",
    "    print(f'execution done --- time cost: [{datetime.now(KST) - start}]')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### inference.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ./inference.py\n",
    "import glob\n",
    "import pandas as pd\n",
    "\n",
    "from easydict import EasyDict\n",
    "from sklearn import preprocessing\n",
    "from tqdm import tqdm\n",
    "\n",
    "from data_loader import *\n",
    "from lightning import LightningRunner\n",
    "import albumentations as A\n",
    "from albumentations.pytorch.transforms import ToTensorV2\n",
    "\n",
    "from model.models import BaseModel\n",
    "\n",
    "\n",
    "args = EasyDict()\n",
    "\n",
    "args.img_size = 512\n",
    "args.batch_size = 1\n",
    "\n",
    "\n",
    "test_transform = A.Compose([\n",
    "                            A.Resize(args.img_size,args.img_size),\n",
    "                            A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225), max_pixel_value=255.0, always_apply=False, p=1.0),\n",
    "                            ToTensorV2()\n",
    "                            ])\n",
    "\n",
    "le = preprocessing.LabelEncoder()\n",
    "\n",
    "all_img_list = glob.glob('./data/train/*/*')\n",
    "df = pd.DataFrame(columns=['img_path', 'label'])\n",
    "df['img_path'] = all_img_list\n",
    "df['label'] = df['img_path'].apply(lambda x : str(x).split('/')[-2])\n",
    "df['label'] = le.fit_transform(df['label'])\n",
    "\n",
    "test = pd.read_csv('/root/Competitions/DACON/Papering_clf/data/test.csv')\n",
    "path = test['img_path'].values\n",
    "path = [f'/root/Competitions/DACON/Papering_clf/data/test/{file.split(\"/\")[-1]}' for file in path]\n",
    "\n",
    "\n",
    "test_dataset = CustomDataset(path, None, test_transform)\n",
    "test_loader = DataLoader(test_dataset, batch_size=args.batch_size, shuffle=False, num_workers=0)\n",
    "\n",
    "model = BaseModel(19)\n",
    "\n",
    "ckpt = '/root/Competitions/DACON/Papering_clf/lightning_logs/[1 Fold] -m ConvNeXt_base, -d A, -t GV || lr=[8e-05], img=[512], bz=[32]/checkpoints/BaseModel-epoch=059-train_loss=0.7751-avg_f1=0.8802.ckpt'\n",
    "pl_runner = LightningRunner.load_from_checkpoint(ckpt, network=model, args=args)\n",
    "\n",
    "DEVICE = 'cuda:1'\n",
    "pl_runner.to(DEVICE)\n",
    "pl_runner.eval()\n",
    "\n",
    "inferences = []\n",
    "for x in tqdm(test_loader):\n",
    "    x = x.to(DEVICE)\n",
    "\n",
    "    pred = pl_runner.model(x)\n",
    "    inferences += pred.argmax(1).detach().cpu().numpy().tolist()\n",
    "\n",
    "    del x \n",
    "\n",
    "inferences = le.inverse_transform(inferences)\n",
    "submit = pd.read_csv('/root/Competitions/DACON/Papering_clf/data/sample_submission.csv')\n",
    "submit['label'] = inferences\n",
    "submit.to_csv('/root/Competitions/DACON/Papering_clf/prediction/[1f] -m ConvNeXt_b, -d A, -t GV || lr=[8e-05], img=[512], bz=[32], pim=[512](-epc=059-loss=0.7751-f1=0.8802).csv', index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### lightning.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ./lightning.py\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "from timm.loss import AsymmetricLossSingleLabel\n",
    "from timm.data import Mixup\n",
    "from timm.data.random_erasing import RandomErasing\n",
    "\n",
    "from sklearn.metrics import classification_report, f1_score\n",
    "import numpy as np\n",
    "from functools import partial\n",
    "from cosine_annealing_warmup import CosineAnnealingWarmupRestarts\n",
    "from model.apollo import Apollo\n",
    "from adamp import AdamP\n",
    "\n",
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, alpha=1, gamma=2, reduce=True):\n",
    "        super(FocalLoss, self).__init__()\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        self.reduce = reduce\n",
    "\n",
    "    def forward(self, inputs, targets):\n",
    "    \n",
    "        ce_loss = nn.CrossEntropyLoss()(inputs, targets)\n",
    "\n",
    "        pt = torch.exp(-ce_loss)  # CE(pt) = -log(pt) --> -ce_loss = log(pt) --> exp(log(pt)) --> pt\n",
    "        F_loss = self.alpha * (1-pt)**self.gamma * ce_loss\n",
    "\n",
    "        if self.reduce:\n",
    "            return torch.mean(F_loss)\n",
    "        else:\n",
    "            return F_loss\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class LightningRunner(pl.LightningModule):\n",
    "    def __init__(self, network, args) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        self.model = network\n",
    "        self.loss = FocalLoss()\n",
    "        # self.loss = LADELoss(args.num_cls, args.prior)\n",
    "        self.args = args\n",
    "        self.traget_names=[f'cls{idx}' for idx in range(19)]\n",
    "\n",
    "        mixup_args = {\n",
    "            'mixup_alpha': 0.3,\n",
    "            'cutmix_alpha': 0.5,\n",
    "            'cutmix_minmax': None,\n",
    "            'prob': 1.0,\n",
    "            'switch_prob': 0.5,\n",
    "            'mode': 'batch',\n",
    "            'label_smoothing': 0.1,\n",
    "            'num_classes': 19}\n",
    "\n",
    "        self.mixup_fn = Mixup(**mixup_args)\n",
    "        # self.rand_erase = RandomErasing(probability=0.5)\n",
    "\n",
    "        # val archieve\n",
    "        self.preds = []\n",
    "        self.true_labels = []\n",
    "        self.loss_log = []\n",
    "\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = AdamP(params=self.parameters(), lr=self.args.init_lr, betas=[0.9, 0.999], weight_decay=0.05)\n",
    "        lr_scheduler = CosineAnnealingWarmupRestarts(optimizer=optimizer, first_cycle_steps=self.args.epochs, max_lr=self.args.init_lr, min_lr=self.args.init_lr*0.001, warmup_steps=self.args.epochs//10, gamma=0.8)\n",
    "        return [optimizer], [lr_scheduler]\n",
    "    \n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        # x = self.rand_erase(x)\n",
    "\n",
    "        if (x.shape[0] % 2 == 0):\n",
    "                x, y = self.mixup_fn(x, y)\n",
    "\n",
    "        y_hat = self.model(x)\n",
    "        loss = self.loss(y_hat, y)\n",
    "        self.log(\"train_loss\", loss, on_step=False, on_epoch=True, prog_bar=True, logger=True, batch_size=self.args.batch_size, sync_dist=True)\n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        self._shared_eval_step(batch, batch_idx)\n",
    "\n",
    "    def on_validation_epoch_end(self) -> None:\n",
    "\n",
    "        val_loss = np.mean(self.loss_log)\n",
    "        \n",
    "        avg_f1 = f1_score(self.true_labels, self.preds, average='weighted')\n",
    "        self.log_dict({'val_loss':val_loss, 'avg_f1':avg_f1}, prog_bar=True, sync_dist=True)\n",
    "\n",
    "        if len(np.unique(self.true_labels)) == 19:\n",
    "            report = classification_report(self.true_labels, self.preds, target_names=self.traget_names)\n",
    "            report_lines = report.split('\\n')\n",
    "\n",
    "            for line in report_lines[2: 2+len(self.traget_names)]:\n",
    "                cls_name, *cls_metrics, support = line.split()\n",
    "                self.log_dict({\n",
    "                    f'precision/{cls_name}': torch.Tensor([float(cls_metrics[0])]),\n",
    "                    f'recall/{cls_name}': torch.Tensor([float(cls_metrics[1])]),\n",
    "                    f'f1-score/{cls_name}': torch.Tensor([float(cls_metrics[2])]),\n",
    "                    f'support/{cls_name}': torch.Tensor([float(support)]),\n",
    "                })\n",
    "            \n",
    "\n",
    "        self.loss_log.clear()\n",
    "        self.true_labels.clear()\n",
    "        self.preds.clear()\n",
    "\n",
    "    def _shared_eval_step(self, batch, batch_idx):\n",
    "        imgs,  labels = batch\n",
    "\n",
    "        y_hat = self.model(imgs)\n",
    "        loss = self.loss(y_hat, labels)\n",
    "\n",
    "        self.preds += y_hat.argmax(1).detach().cpu().numpy().tolist()\n",
    "        self.true_labels += labels.detach().cpu().numpy().tolist()\n",
    "        self.loss_log.append(loss.item())\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### data_loader.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ./data_loader.py\n",
    "import cv2\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, img_path_list, label_list, transforms=None):\n",
    "        self.img_path_list = img_path_list\n",
    "        self.label_list = label_list\n",
    "        self.transforms = transforms\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        img_path = self.img_path_list[index]\n",
    "        \n",
    "        image = cv2.imread(img_path)\n",
    "        \n",
    "        if self.transforms is not None:\n",
    "            image = self.transforms(image=image)['image']\n",
    "\n",
    "        if self.label_list is not None:\n",
    "            label = self.label_list[index]\n",
    "            return image, label\n",
    "        else:\n",
    "            return image\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.img_path_list)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### stratifiedKfold_pl_data.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ./stratifiedKfold_pl_data.py \n",
    "import os\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "import glob\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "from sklearn import preprocessing\n",
    "\n",
    "from data_loader import CustomDataset\n",
    "\n",
    "class KFold_pl_DataModule(pl.LightningDataModule):\n",
    "    def __init__(self,\n",
    "                 data_dir: str = None,\n",
    "                 k_idx: int =1, # fold index\n",
    "                 num_split: int = 5, # fold number, if k=1 then return the whole data\n",
    "                 split_seed: int = 41,\n",
    "                 batch_size: int = 2, \n",
    "                 num_workers: int = 0,\n",
    "                 pin_memory: bool = False,\n",
    "                 persistent_workers: bool=True,\n",
    "                 train_transform=None,\n",
    "                 val_transform =None\n",
    "                 ) -> None:\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters(logger=False)\n",
    "\n",
    "        self.train_data = None\n",
    "        self.val_data = None\n",
    "        self.num_cls = 0\n",
    "\n",
    "    def setup(self, stage: str) -> None:\n",
    "        if not self.train_data and not self.val_data:\n",
    "            all_img_list = glob.glob(self.hparams.data_dir)\n",
    "            df = pd.DataFrame(columns=['img_path', 'label'])\n",
    "            df['img_path'] = all_img_list\n",
    "            df['label'] = df['img_path'].apply(lambda x : str(x).split('/')[-2])\n",
    "\n",
    "            kf = StratifiedKFold(n_splits=self.hparams.num_split,\n",
    "                       shuffle=True,\n",
    "                       random_state=self.hparams.split_seed)\n",
    "            \n",
    "            all_splits = [k for k in kf.split(df, df['label'])]\n",
    "            train_idx, val_idx = all_splits[self.hparams.k_idx]\n",
    "            train_idx, val_idx = train_idx.tolist(), val_idx.tolist()\n",
    "\n",
    "            train = df.iloc[train_idx]\n",
    "            val = df.iloc[val_idx]\n",
    "\n",
    "            le = preprocessing.LabelEncoder()\n",
    "            le.fit(df['label'])\n",
    "            train['label'] = le.transform(train['label'])\n",
    "            val['label'] = le.transform(val['label'])\n",
    "            self.num_cls = len(le.classes_)\n",
    "\n",
    "\n",
    "            \n",
    "            self.train_data = CustomDataset(train['img_path'].values, train['label'].values, self.hparams.train_transform)\n",
    "            self.val_data = CustomDataset(val['img_path'].values, val['label'].values, self.hparams.val_transform)\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.train_data,\n",
    "                          batch_size=self.hparams.batch_size,\n",
    "                          shuffle=True,\n",
    "                          num_workers=self.hparams.num_workers,\n",
    "                          persistent_workers=self.hparams.persistent_workers,\n",
    "                          pin_memory=self.hparams.pin_memory)\n",
    "    \n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(self.val_data,\n",
    "                          batch_size=self.hparams.batch_size//2,\n",
    "                          shuffle=False,\n",
    "                          num_workers=self.hparams.num_workers,\n",
    "                          persistent_workers=self.hparams.persistent_workers,\n",
    "                          pin_memory=self.hparams.pin_memory)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### runner.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  ./runner.py\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    from easydict import EasyDict\n",
    "\n",
    "    from sklearn import preprocessing\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from lightning_fabric.utilities.seed import seed_everything\n",
    "\n",
    "    from pytorch_lightning import Trainer\n",
    "    from pytorch_lightning.strategies.ddp import DDPStrategy\n",
    "    from pytorch_lightning.callbacks import ModelCheckpoint, LearningRateMonitor, LearningRateFinder\n",
    "    from pytorch_lightning.loggers.tensorboard import TensorBoardLogger\n",
    "    from pytorch_lightning import tuner as Tuner\n",
    "\n",
    "    import albumentations as A\n",
    "    from albumentations.pytorch.transforms import ToTensorV2\n",
    "\n",
    "    import glob    \n",
    "    import pandas as pd\n",
    "\n",
    "\n",
    "    from lightning import LightningRunner\n",
    "    from data_loader import *\n",
    "    from model.models import *\n",
    "    from torch.utils.data import DataLoader\n",
    "\n",
    "    args = EasyDict()\n",
    "\n",
    "    args.img_size = 368\n",
    "\n",
    "    args.batch_size = 32\n",
    "    args.epochs = 80\n",
    "    args.init_lr = 8e-5\n",
    "    args.weight_decay = 0.05\n",
    "\n",
    "    args.seed = 1120\n",
    "    \n",
    "\n",
    "    seed_everything(args.seed)\n",
    "\n",
    "    \n",
    "\n",
    "    all_img_list = glob.glob('./aug_data/train/*/*')\n",
    "    df = pd.DataFrame(columns=['img_path', 'label'])\n",
    "    df['img_path'] = all_img_list\n",
    "    df['label'] = df['img_path'].apply(lambda x : str(x).split('/')[-2])\n",
    " \n",
    "\n",
    "    train, val, _, _ = train_test_split(df, df['label'], test_size=0.3, stratify=df['label'], random_state=args.seed)\n",
    "\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    train['label'] = le.fit_transform(train['label'])\n",
    "    val['label'] = le.transform(val['label'])\n",
    "\n",
    "    args.prior = df.label.value_counts().to_frame().sort_index().values\n",
    "    args.num_cls = len(le.classes_)\n",
    "\n",
    "\n",
    "    train_transform_4_origin = A.Compose([\n",
    "                            A.Resize(args.img_size,args.img_size),\n",
    "                            A.AdvancedBlur(),\n",
    "                            A.ColorJitter(),\n",
    "                            A.GaussNoise(),\n",
    "                            A.OpticalDistortion(distort_limit=(-0.3, 0.3), shift_limit=0.5, p=0.5),\n",
    "                            A.HorizontalFlip(),\n",
    "                            A.Affine(scale=(0.9, 2), translate_percent=(-0.1, 0.1), rotate=(-10, 10), shear=(-20,20)),\n",
    "                            A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225), max_pixel_value=255.0, always_apply=False, p=1.0),\n",
    "                            A.ElasticTransform(alpha=300),\n",
    "                            ToTensorV2()\n",
    "                            ])\n",
    "    \n",
    "    test_transform = A.Compose([\n",
    "                            A.Resize(args.img_size,args.img_size),\n",
    "                            A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225), max_pixel_value=255.0, always_apply=False, p=1.0),\n",
    "                            ToTensorV2()\n",
    "                            ])\n",
    "\n",
    "\n",
    "    train_dataset = CustomDataset(train['img_path'].values, train['label'].values, train_transform_4_origin)\n",
    "    train_loader = DataLoader(train_dataset, batch_size = args.batch_size, shuffle=True, num_workers=4)\n",
    "\n",
    "    val_dataset = CustomDataset(val['img_path'].values, val['label'].values, test_transform)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=args.batch_size//2, shuffle=False, num_workers=4)\n",
    "\n",
    "    model = BaseModel(len(le.classes_))\n",
    "    pl_runner = LightningRunner(model, args)\n",
    "    lr_monitor = LearningRateMonitor(logging_interval='step')\n",
    "\n",
    "    \n",
    "    # lr_finder = LearningRateFinder(num_training_steps=8000)\n",
    "    checkpoint_callback = ModelCheckpoint(\n",
    "        monitor='avg_f1',\n",
    "        filename=f'{model.__class__.__name__}'+'-{epoch:03d}-{train_loss:.4f}-{avg_f1:.4f}',\n",
    "        mode='max'\n",
    "    )\n",
    "\n",
    "    logger = TensorBoardLogger(\n",
    "        save_dir='.',\n",
    "        version='LEARNING CHECK',\n",
    "        # version=f'[S.7] --m ConvNeXt, --d A, --t GV --L F long || lr=[{args.init_lr}], img=[{args.img_size}], bz=[{args.batch_size}]'\n",
    "        )\n",
    "\n",
    "    trainer = Trainer(\n",
    "        max_epochs=args.epochs,\n",
    "        devices=[0],\n",
    "        accelerator='gpu',\n",
    "        precision='16-mixed',\n",
    "        # strategy=DDPStrategy(find_unused_parameters=False),\n",
    "        callbacks=[lr_monitor, checkpoint_callback],\n",
    "        # check_val_every_n_epoch=2,py\n",
    "        check_val_every_n_epoch=2,\n",
    "        # log_every_n_steps=1,\n",
    "        logger=logger,\n",
    "        # auto_lr_find=True\n",
    "        # accumulate_grad_batches=2\n",
    "        )\n",
    "\n",
    "\n",
    "    trainer.fit(\n",
    "        model= pl_runner,\n",
    "        train_dataloaders=train_loader,\n",
    "        val_dataloaders=val_loader\n",
    "        # datamodule=pl_data\n",
    "    )\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### models.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ./model/models.py\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "\n",
    "class BaseModel(nn.Module):\n",
    "    def __init__(self, num_classes:int):\n",
    "        super(BaseModel, self).__init__()\n",
    "        \n",
    "        self.backbone = models.convnext_large(weights=models.ConvNeXt_Large_Weights.DEFAULT)\n",
    "        self.norm = nn.LayerNorm(1000)\n",
    "        self.act = nn.SiLU()\n",
    "        self.drop = nn.Dropout1d()\n",
    "        self.classifier = nn.Linear(1000, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.backbone(x)\n",
    "        x = self.norm(x)\n",
    "        x = self.act(x)\n",
    "        x = self.drop(x)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "    \n",
    "    \n",
    "# def replace_module(modules:nn.Module, target, source):\n",
    "#         for name, child in modules.named_children():\n",
    "#             if isinstance(child, target):\n",
    "#                 modules._modules[name] = source()\n",
    "#             # elif isinstance(child, nn.Sequential):\n",
    "#             else: \n",
    "#                 replace_module(child, target, source)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
