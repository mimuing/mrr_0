{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# BEiT + CutMix + CosineEmbeddingLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 112690,
     "status": "ok",
     "timestamp": 1645972270802,
     "user": {
      "displayName": "‍김태형[ 대학원석·박사통합과정재학 / 산업경영공학과 ]",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjFNpnkjN-Em0rOki5hhy0HR7yGAbxSpzCjHV0A=s64",
      "userId": "00288066936238655028"
     },
     "user_tz": -540
    },
    "id": "A1IbqGhzB7fy",
    "outputId": "fd656f36-afcb-4871-ee1c-557fd033af76"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "# %matplotlib inline\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "from PIL import Image\n",
    "from torchvision.transforms import v2\n",
    "import torchvision.models as models\n",
    "\n",
    "import cv2\n",
    "import albumentations as A\n",
    "\n",
    "import transformers\n",
    "from transformers import AutoImageProcessor, AutoModel\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from argparse import ArgumentParser\n",
    "\n",
    "parser = ArgumentParser(description=\"lowreso_imgclf\")\n",
    "parser.add_argument('--image_pretrained_model', default=\"beit-base-patch16-224-pt22k-ft22k\", type=str)\n",
    "parser.add_argument('--image_size', default=224, type=int)\n",
    "parser.add_argument('--aug_p', default=1, type=float)\n",
    "parser.add_argument('--optimizer', default=\"adamw\", type=str)\n",
    "parser.add_argument('--learning_rate', default=0.00003, type=float)\n",
    "parser.add_argument('--scheduler', default=\"cosine\", type=str)\n",
    "parser.add_argument('--batch_size', default=64, type=int)\n",
    "parser.add_argument('--epochs', default=10, type=int)\n",
    "parser.add_argument('--cv', default=5, type=int)\n",
    "parser.add_argument('--seed', default=826, type=int)\n",
    "parser.add_argument('--mixed_precision', default=16, type=int)\n",
    "parser.add_argument('--device', nargs='+', default=[0], type=int)\n",
    "parser.add_argument('--num_workers', default=0, type=int)\n",
    "args = parser.parse_args('')\n",
    "\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "image_size = args.image_size\n",
    "aug_p = args.aug_p\n",
    "BATCH_SIZE = args.batch_size\n",
    "EPOCHS = args.epochs\n",
    "CV = args.cv\n",
    "SEED = args.seed\n",
    "\n",
    "def set_seeds(seed=SEED):\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    pl.seed_everything(SEED)\n",
    "\n",
    "set_seeds()\n",
    "\n",
    "idx = f\"{args.image_pretrained_model}\"\n",
    "idx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## config.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BEiT, DINOv2\n",
    "\n",
    "if args.image_pretrained_model == \"beit-base-patch16-224-pt22k-ft22k\": # acc@1 : 85.2\n",
    "    img_model_name = \"microsoft/beit-base-patch16-224-pt22k-ft22k\"\n",
    "    latent_dim = 768\n",
    "if args.image_pretrained_model == \"dinov2-large\":\n",
    "    img_model_name = \"facebook/dinov2-large\"\n",
    "    latent_dim = 1024\n",
    "\n",
    "processor = AutoImageProcessor.from_pretrained(img_model_name)\n",
    "# img_model = AutoModel.from_pretrained(img_model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('data/train.csv')\n",
    "test_df = pd.read_csv('data/test.csv')\n",
    "\n",
    "train_df[\"img_path\"] = train_df[\"img_path\"].apply(lambda x : \"data\"+x[1:])\n",
    "test_df[\"img_path\"] = test_df[\"img_path\"].apply(lambda x : \"data\"+x[1:])\n",
    "\n",
    "train_df[\"upscale_img_path\"] = train_df[\"upscale_img_path\"].apply(lambda x : \"data\"+x[1:])\n",
    "\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df[\"label\"].value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = train_df[\"label\"]\n",
    "label_unique = sorted(np.unique(train_labels))\n",
    "label_unique = {key : value for key, value in zip(label_unique, range(len(label_unique)))}\n",
    "\n",
    "label_unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df[\"label\"] = train_df[\"label\"].apply(lambda x : label_unique[x])\n",
    "\n",
    "train_df[\"label\"].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## data_loader.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## torchvision v2\n",
    "\n",
    "cutmix = v2.CutMix(num_classes=len(label_unique))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, df, img_path, is_test=False, transform=None):\n",
    "        self.df = df\n",
    "        self.processor = processor\n",
    "        self.img_path = img_path\n",
    "        self.is_test = is_test\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        \n",
    "        image = cv2.imread(row[self.img_path])\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        if not self.is_test:\n",
    "\n",
    "            image = cv2.imread(row[self.img_path])\n",
    "            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "            encoding = self.processor(\n",
    "                images=image,\n",
    "                return_tensors=\"pt\"\n",
    "            )\n",
    "\n",
    "            encoding[\"labels\"] = torch.tensor(row['label'], dtype=torch.long)\n",
    "            \n",
    "            for k,v in encoding.items():\n",
    "                encoding[k] = v.squeeze()\n",
    "\n",
    "            return encoding\n",
    "            \n",
    "        encoding = self.processor(\n",
    "            images=image,\n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "\n",
    "        for k,v in encoding.items():\n",
    "            encoding[k] = v.squeeze()\n",
    "\n",
    "        return encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## model.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.model = AutoModel.from_pretrained(img_model_name)\n",
    "        self.clf = nn.Linear(latent_dim, len(label_unique))\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        enc = self.model(inputs)\n",
    "        x = enc.pooler_output\n",
    "        outputs = self.clf(x)\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageClassifier(pl.LightningModule):\n",
    "    def __init__(self, backbone, args):\n",
    "        super().__init__()\n",
    "        self.backbone = backbone\n",
    "\n",
    "    def forward(self, x):\n",
    "        outputs = self.backbone(x)\n",
    "        return outputs\n",
    "\n",
    "    def step(self, batch):\n",
    "        x = batch[\"pixel_values\"]\n",
    "        y = batch[\"labels\"]\n",
    "        y_hat = self.forward(x)\n",
    "        loss = nn.CrossEntropyLoss()(y_hat, y)\n",
    "        return loss, y, y_hat\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        loss_ce, y, y_hat = self.step(batch)\n",
    "        loss_cos = nn.CosineEmbeddingLoss()(\n",
    "            y_hat, y, torch.Tensor([1]).to(self.device)\n",
    "        )\n",
    "        loss = loss_ce + loss_cos\n",
    "        f1 = f1_score(y_hat.max(dim=1)[1].cpu().numpy(), y.max(dim=1)[1].cpu().numpy(), average='macro')\n",
    "        self.log('train_loss', loss, on_step=False, on_epoch=True, prog_bar=True)\n",
    "        self.log(\"train_f1\", f1, on_step=False, on_epoch=True, prog_bar=True)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        loss_ce, y, y_hat = self.step(batch)\n",
    "        loss_cos = nn.CosineEmbeddingLoss()(\n",
    "            y_hat, F.one_hot(y.long(), len(label_unique)), torch.Tensor([1]).to(self.device)\n",
    "        )\n",
    "        loss = loss_ce + loss_cos\n",
    "        f1 = f1_score(y_hat.max(dim=1)[1].cpu().numpy(), y.cpu().numpy(), average='macro')\n",
    "        self.log('val_loss', loss, on_epoch=True, prog_bar=True)\n",
    "        self.log(\"val_f1\", f1, on_epoch=True, prog_bar=True)\n",
    "        return loss\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        loss, y, y_hat = self.step(batch)\n",
    "        f1 = f1_score(y_hat.max(dim=1)[1].cpu().numpy(), y.cpu().numpy(), average='macro')\n",
    "        self.log(\"test_f1\", f1)\n",
    "\n",
    "    def predict_step(self, batch, batch_idx, dataloader_idx=0):\n",
    "        x = batch[\"pixel_values\"]\n",
    "        y_hat = self.forward(x)\n",
    "        return y_hat\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        if args.optimizer == \"sgd\":\n",
    "            optimizer = torch.optim.SGD(self.parameters(), lr=args.learning_rate, momentum=0.9)\n",
    "        if args.optimizer == \"adam\":\n",
    "            optimizer = torch.optim.Adam(self.parameters(), lr=args.learning_rate)\n",
    "        if args.optimizer == \"adamw\":\n",
    "            optimizer = torch.optim.AdamW(self.parameters(), lr=args.learning_rate)\n",
    "        \n",
    "        if args.scheduler == \"none\":\n",
    "            return optimizer\n",
    "        if args.scheduler == \"cosine\":\n",
    "            scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(\n",
    "                optimizer=optimizer,\n",
    "                T_max=args.epochs//2,\n",
    "                eta_min=args.learning_rate//10,\n",
    "            )\n",
    "            return [optimizer], [scheduler]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## main.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import default_collate\n",
    "\n",
    "def collate_fn(batch):\n",
    "    data = default_collate(batch)\n",
    "    data = cutmix(data['pixel_values'], data['labels'])\n",
    "    data_dict = {\n",
    "        'pixel_values' : data[0],\n",
    "        'labels' : data[1],\n",
    "    }\n",
    "    return data_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## preprocessing.py\n",
    "\n",
    "val_f1_list = []\n",
    "preds_list = []\n",
    "\n",
    "skf = StratifiedKFold(n_splits=CV, shuffle=True, random_state=SEED)\n",
    "\n",
    "for i, (train_index, val_index) in enumerate(skf.split(train_df, train_df[\"label\"])):\n",
    "\n",
    "    temp_df = train_df.iloc[train_index]\n",
    "    val_df = train_df.iloc[val_index]\n",
    "\n",
    "## data_loaders.py\n",
    "    \n",
    "    train_ds_low = ImageDataset(temp_df, \"img_path\", is_test=False)\n",
    "    train_ds_high = ImageDataset(temp_df, \"upscale_img_path\", is_test=False)\n",
    "    train_ds = train_ds_low + train_ds_high\n",
    "    val_ds = ImageDataset(val_df, \"img_path\", is_test=False) \n",
    "    test_ds = ImageDataset(test_df, \"img_path\", is_test=True)\n",
    "    \n",
    "    train_dataloader = DataLoader(\n",
    "        train_ds, batch_size=BATCH_SIZE, shuffle=True, num_workers=args.num_workers,\n",
    "        ## torchvision v2\n",
    "        collate_fn=collate_fn\n",
    "    )\n",
    "    val_dataloader = DataLoader(\n",
    "        val_ds, batch_size=BATCH_SIZE, shuffle=False, num_workers=args.num_workers\n",
    "    )\n",
    "    test_dataloader = DataLoader(\n",
    "        test_ds, batch_size=BATCH_SIZE, shuffle=False, num_workers=args.num_workers\n",
    "    )\n",
    "\n",
    "## train.py\n",
    "\n",
    "    model = ImageClassifier(ImageModel(), args)\n",
    "\n",
    "    callbacks = [\n",
    "        # pl.callbacks.EarlyStopping(\n",
    "        #     monitor=\"val_f1\", patience=5, mode=\"max\"\n",
    "        # ),\n",
    "        pl.callbacks.ModelCheckpoint(\n",
    "            dirpath=\"saved/\", filename=f\"{idx}_{i}\",\n",
    "            monitor=\"val_f1\", mode=\"max\"\n",
    "        ),\n",
    "    ]\n",
    "\n",
    "    trainer = pl.Trainer(\n",
    "        max_epochs=EPOCHS, accelerator=\"auto\", callbacks=callbacks,\n",
    "        precision=args.mixed_precision, #logger=wandb_logger,\n",
    "        devices=args.device, #strategy='ddp_find_unused_parameters_true'\n",
    "    )\n",
    "\n",
    "    trainer.fit(model, train_dataloader, val_dataloader)\n",
    "    \n",
    "    ckpt = torch.load(f\"saved/{idx}_{i}.ckpt\", map_location=torch.device(device))\n",
    "    model.load_state_dict(ckpt['state_dict'])\n",
    "\n",
    "## test.py\n",
    "\n",
    "    eval_dict = trainer.validate(model, dataloaders=val_dataloader)[0]\n",
    "    val_f1_list.append(eval_dict[\"val_f1\"])\n",
    "\n",
    "    y_preds = trainer.predict(model, dataloaders=test_dataloader)\n",
    "\n",
    "    y_pred = np.vstack(y_preds)\n",
    "    # np.save(f'saved/{idx}_{i}', y_pred)\n",
    "\n",
    "    preds_list.append(y_pred)\n",
    "    \n",
    "val_f1_mean = np.mean(val_f1_list)\n",
    "print(f\"val_f1_mean: {val_f1_mean}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = np.mean(preds_list, axis=0)\n",
    "# np.save(f'saved/{idx}_ensemble', y_pred)\n",
    "preds = y_pred.argmax(axis=1)\n",
    "\n",
    "preds.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_decoder = {val:key for key, val in label_unique.items()}\n",
    "result = [label_decoder[result] for result in preds]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit = pd.read_csv('data/sample_submission.csv')\n",
    "submit[\"label\"] = result\n",
    "submit.to_csv(f'{idx}.csv', index=False)\n",
    "\n",
    "submit.head()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyPxWDbXdBZDPv2XiwW8C1k0",
   "collapsed_sections": [],
   "mount_file_id": "13o4BpF8zzuXcEiNVlVG2KwTXMW1Y55_v",
   "name": "test.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
