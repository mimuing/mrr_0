{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XoJGJyu8sF9X",
        "outputId": "1822e86b-5e16-4690-ee0e-82d63080a1f3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jZrHx35ZsKGn",
        "outputId": "ac5fed50-1c97-48e7-eefb-26704df764be"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/dacon/lowresol\n"
          ]
        }
      ],
      "source": [
        "cd /content/drive/MyDrive/dacon/lowresol/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6FkfVK0DDsdI"
      },
      "outputs": [],
      "source": [
        "# !unzip -qn open.zip -d ./data/"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --quiet timm pytorch_lightning==1.7.7 torchmetrics==0.11.1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iUhtm616SjZN",
        "outputId": "9862f862-2e0c-4e34-f0d2-5df4c2f92af0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m708.1/708.1 kB\u001b[0m \u001b[31m23.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m517.2/517.2 kB\u001b[0m \u001b[31m22.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import gc\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "import pytorch_lightning as L\n",
        "\n",
        "from glob import glob\n",
        "from tqdm.auto import tqdm\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from torchvision.io import read_image\n",
        "from torchvision.transforms import v2 as  transforms\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from transformers import Swinv2Config, Swinv2Model, AutoImageProcessor, AutoModelForImageClassification\n",
        "from pytorch_lightning.callbacks import ModelCheckpoint\n",
        "from pytorch_lightning.callbacks.early_stopping import EarlyStopping"
      ],
      "metadata": {
        "id": "k95fPjnRSjV0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, df, path_col,  mode='train'):\n",
        "        self.df = df\n",
        "        self.path_col = path_col\n",
        "        self.mode = mode\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        if self.mode == 'train':\n",
        "            row = self.df.iloc[idx]\n",
        "            image = read_image(row[self.path_col])/256.\n",
        "            label = row['class']\n",
        "            data = {\n",
        "                'image':image,\n",
        "                'label':label\n",
        "            }\n",
        "            return data\n",
        "        elif self.mode == 'val':\n",
        "            row = self.df.iloc[idx]\n",
        "            image = read_image(row[self.path_col])/256.\n",
        "            label = row['class']\n",
        "            data = {\n",
        "                'image':image,\n",
        "                'label':label\n",
        "            }\n",
        "            return data\n",
        "        elif self.mode == 'inference':\n",
        "            row = self.df.iloc[idx]\n",
        "            image = read_image(row[self.path_col])/256.\n",
        "            data = {\n",
        "                'image':image,\n",
        "            }\n",
        "            return data\n",
        "\n",
        "    def train_transform(self, image):\n",
        "        pass"
      ],
      "metadata": {
        "id": "kCL6U72NSxNp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomCollateFn:\n",
        "    def __init__(self, transform, mode):\n",
        "        self.mode = mode\n",
        "        self.transform = transform\n",
        "\n",
        "    def __call__(self, batch):\n",
        "        if self.mode=='train':\n",
        "            pixel_values = torch.stack([self.transform(data['image']) for data in batch])\n",
        "            label = torch.LongTensor([data['label'] for data in batch])\n",
        "            return {\n",
        "                'pixel_values':pixel_values,\n",
        "                'label':label,\n",
        "            }\n",
        "        elif self.mode=='val':\n",
        "            pixel_values = torch.stack([self.transform(data['image']) for data in batch])\n",
        "            label = torch.LongTensor([data['label'] for data in batch])\n",
        "            return {\n",
        "                'pixel_values':pixel_values,\n",
        "                'label':label,\n",
        "            }\n",
        "        elif self.mode=='inference':\n",
        "            pixel_values = torch.stack([self.transform(data['image']) for data in batch])\n",
        "            return {\n",
        "                'pixel_values':pixel_values,\n",
        "            }\n"
      ],
      "metadata": {
        "id": "edqWSq6JSxLb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomModel(nn.Module):\n",
        "    def __init__(self, model):\n",
        "        super(CustomModel, self).__init__()\n",
        "        self.model = model\n",
        "        self.clf = nn.Sequential(\n",
        "            nn.Tanh(),\n",
        "            nn.LazyLinear(25),\n",
        "        )\n",
        "\n",
        "#     @torch.compile\n",
        "    def forward(self, x, label=None):\n",
        "        x = self.model(x).pooler_output\n",
        "        x = self.clf(x)\n",
        "        loss = None\n",
        "        if label is not None:\n",
        "            loss = nn.CrossEntropyLoss()(x, label)\n",
        "        probs = nn.LogSoftmax(dim=-1)(x)\n",
        "        return probs, loss\n",
        "\n",
        "class LitCustomModel(L.LightningModule):\n",
        "    def __init__(self, model):\n",
        "        super().__init__()\n",
        "        self.model = CustomModel(model)\n",
        "        self.validation_step_output = []\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        opt = torch.optim.AdamW(self.parameters(), lr=1e-5)\n",
        "        return opt\n",
        "\n",
        "    def training_step(self, batch, batch_idx=None):\n",
        "        x = batch['pixel_values']\n",
        "        label = batch['label']\n",
        "        probs, loss = self.model(x, label)\n",
        "        self.log(f\"train_loss\", loss, on_step=True, on_epoch=False)\n",
        "        return loss\n",
        "\n",
        "    def validation_step(self, batch, batch_idx=None):\n",
        "        x = batch['pixel_values']\n",
        "        label = batch['label']\n",
        "        probs, loss = self.model(x, label)\n",
        "        self.validation_step_output.append([probs,label])\n",
        "        return loss\n",
        "\n",
        "    def predict_step(self, batch, batch_idx=None):\n",
        "        x = batch['pixel_values']\n",
        "        probs, _ = self.model(x)\n",
        "        return probs\n",
        "\n",
        "    def validation_epoch_end(self, step_output):\n",
        "        pred = torch.cat([x for x, _ in self.validation_step_output]).cpu().detach().numpy().argmax(1)\n",
        "        label = torch.cat([label for _, label in self.validation_step_output]).cpu().detach().numpy()\n",
        "        score = f1_score(label,pred, average='macro')\n",
        "        self.log(\"val_score\", score)\n",
        "        self.validation_step_output.clear()\n",
        "        return score"
      ],
      "metadata": {
        "id": "TfQfZc6lSxJD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "SEED = 42\n",
        "N_SPLIT = 5\n",
        "BATCH_SIZE = 12"
      ],
      "metadata": {
        "id": "n4qX0V8CSjTB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "L.seed_everything(SEED)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zfs809d7SjQl",
        "outputId": "ec4078ab-c069-413a-e3a6-fc856d3a55de"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pytorch_lightning.utilities.seed:Global seed set to 42\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "42"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_df = pd.read_csv('./data/train.csv')\n",
        "train_df['img_path'] = train_df['img_path'].apply(lambda x: os.path.join('./data', x))\n",
        "train_df['upscale_img_path'] = train_df['upscale_img_path'].apply(lambda x: os.path.join('./data', x))\n",
        "le = LabelEncoder()\n",
        "train_df['class'] = le.fit_transform(train_df['label'])"
      ],
      "metadata": {
        "id": "VoWIJtWISjOC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if not len(train_df) == len(os.listdir('./data/train')):\n",
        "    raise ValueError()"
      ],
      "metadata": {
        "id": "vj2Tb6MuTL5b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "skf = StratifiedKFold(n_splits=N_SPLIT, random_state=SEED, shuffle=True)"
      ],
      "metadata": {
        "id": "ETmPNpAqSjLe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_transform = transforms.Compose([\n",
        "    transforms.Resize(size=(256,256), interpolation=transforms.InterpolationMode.BICUBIC),\n",
        "    transforms.Normalize(mean=(0.485,0.456,0.406), std=(0.229,0.224,0.225)),\n",
        "])\n",
        "val_transform = transforms.Compose([\n",
        "    transforms.Resize(size=(256,256), interpolation=transforms.InterpolationMode.BICUBIC),\n",
        "    transforms.Normalize(mean=(0.485,0.456,0.406), std=(0.229,0.224,0.225)),\n",
        "])\n",
        "\n",
        "train_collate_fn = CustomCollateFn(train_transform, 'train')\n",
        "val_collate_fn = CustomCollateFn(val_transform, 'val')"
      ],
      "metadata": {
        "id": "t8YcDJ0ITXfp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for fold_idx, (train_index, val_index) in enumerate(skf.split(train_df, train_df['class'])):\n",
        "    train_fold_df = train_df.loc[train_index,:]\n",
        "    val_fold_df = train_df.loc[val_index,:]\n",
        "\n",
        "    train_dataset = CustomDataset(train_fold_df, 'img_path', mode='train')\n",
        "    val_dataset = CustomDataset(val_fold_df, 'img_path', mode='val')\n",
        "\n",
        "    train_dataloader = DataLoader(train_dataset, collate_fn=train_collate_fn, batch_size=BATCH_SIZE)\n",
        "    val_dataloader = DataLoader(val_dataset, collate_fn=val_collate_fn, batch_size=BATCH_SIZE*2)\n",
        "\n",
        "    model = Swinv2Model.from_pretrained(\"microsoft/swinv2-large-patch4-window12to16-192to256-22kto1k-ft\")\n",
        "    lit_model = LitCustomModel(model)\n",
        "\n",
        "    checkpoint_callback = ModelCheckpoint(\n",
        "        monitor='val_score',\n",
        "        mode='max',\n",
        "        dirpath='./checkpoints/',\n",
        "        filename=f'swinv2-large-resize-fold_idx={fold_idx}'+'-{epoch:02d}-{train_loss:.4f}-{val_score:.4f}',\n",
        "        save_top_k=1,\n",
        "        save_weights_only=True,\n",
        "        verbose=True\n",
        "    )\n",
        "    earlystopping_callback = EarlyStopping(monitor=\"val_score\", mode=\"max\", patience=3)\n",
        "    trainer = L.Trainer(max_epochs=100, accelerator='auto', precision=32, callbacks=[checkpoint_callback, earlystopping_callback], val_check_interval=0.5)\n",
        "    trainer.fit(lit_model, train_dataloader, val_dataloader)\n",
        "\n",
        "    model.cpu()\n",
        "    lit_model.cpu()\n",
        "    del model, lit_model, checkpoint_callback, earlystopping_callback, trainer\n",
        "    gc.collect()\n",
        "    torch.cuda.empty_cache()\n"
      ],
      "metadata": {
        "id": "ZvWhUDQ1SjI_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_df = pd.read_csv('./data/test.csv')\n",
        "test_df['img_path'] = test_df['img_path'].apply(lambda x: os.path.join('./data', x))"
      ],
      "metadata": {
        "id": "PgUYnr8YTxhw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if not len(test_df) == len(os.listdir('./data/test')):\n",
        "    raise ValueError()"
      ],
      "metadata": {
        "id": "mnViVzTkTxfV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_transform = transforms.Compose([\n",
        "    transforms.Resize(size=(256,256), interpolation=transforms.InterpolationMode.BICUBIC),\n",
        "    transforms.Normalize(mean=(0.485,0.456,0.406), std=(0.229,0.224,0.225)),\n",
        "])\n",
        "\n",
        "test_collate_fn = CustomCollateFn(test_transform, 'inference')\n",
        "test_dataset = CustomDataset(test_df, 'img_path', mode='inference')\n",
        "test_dataloader = DataLoader(test_dataset, collate_fn=test_collate_fn, batch_size=BATCH_SIZE*2)"
      ],
      "metadata": {
        "id": "8tkcrAzbTxc4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fold_preds = []\n",
        "for checkpoint_path in glob('./checkpoints/swinv2-large-resize*.ckpt'):\n",
        "    model = Swinv2Model.from_pretrained(\"microsoft/swinv2-large-patch4-window12to16-192to256-22kto1k-ft\")\n",
        "    lit_model = LitCustomModel.load_from_checkpoint(checkpoint_path, model=model)\n",
        "    trainer = L.Trainer( accelerator='auto', precision=32)\n",
        "    preds = trainer.predict(lit_model, test_dataloader)\n",
        "    preds = torch.cat(preds,dim=0).detach().cpu().numpy().argmax(1)\n",
        "    fold_preds.append(preds)\n",
        "pred_ensemble = list(map(lambda x: np.bincount(x).argmax(),np.stack(fold_preds,axis=1)))"
      ],
      "metadata": {
        "id": "RZo9oMpITxaP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "submission = pd.read_csv('./data/sample_submission.csv')"
      ],
      "metadata": {
        "id": "mrg3YgZQTwdK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "submission['label'] = le.inverse_transform(pred_ensemble)"
      ],
      "metadata": {
        "id": "5FZpGaIZSjGb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "submission.to_csv('./submissions/swinv2_large_resize.csv',index=False)"
      ],
      "metadata": {
        "id": "7uzSd-s-TG5D"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "V100",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}