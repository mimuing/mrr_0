{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import EfficientNetB0\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications.efficientnet import preprocess_input\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "\n",
    "# EfficientNetB0 모델 불러오기 (ImageNet 가중치 사용)\n",
    "base_model = EfficientNetB0(weights='imagenet', include_top=False, pooling='avg')\n",
    "def extract_features(img_path):\n",
    "    # 이미지 불러오기 및 전처리\n",
    "    img = image.load_img(img_path, target_size=(224, 224))\n",
    "    img_array = image.img_to_array(img)\n",
    "    img_array = np.expand_dims(img_array, axis=0)\n",
    "    img_array = preprocess_input(img_array)\n",
    "    # 특징 추출\n",
    "    features = base_model.predict(img_array)\n",
    "    return features\n",
    "def calculate_similarity(features1, features2):\n",
    "    # 코사인 유사도 계산\n",
    "    return cosine_similarity(features1, features2)[0][0]\n",
    "\n",
    "# 예제 이미지 경로\n",
    "img_path1 = 'path_to_image1.jpg'\n",
    "img_path2 = 'path_to_image2.jpg'\n",
    "# 특징 추출\n",
    "features1 = extract_features(img_path1)\n",
    "features2 = extract_features(img_path2)\n",
    "# 유사도 계산\n",
    "similarity = calculate_similarity(features1, features2)\n",
    "print(f\"두 이미지의 유사도: {similarity}\")\n",
    "# 유사도가 임계값 이상이면 같은 객체로 간주\n",
    "threshold = 0.8\n",
    "if similarity > threshold:\n",
    "    print(\"두 이미지는 같은 객체일 가능성이 높습니다.\")\n",
    "else:\n",
    "    print(\"두 이미지는 다른 객체일 가능성이 높습니다.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import EfficientNetB0\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications.efficientnet import preprocess_input\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# EfficientNetB0 모델 불러오기 (ImageNet 가중치 사용)\n",
    "base_model = EfficientNetB0(weights='imagenet', include_top=False, pooling='avg')\n",
    "\n",
    "def extract_features(img):\n",
    "    # 이미지 전처리\n",
    "    img_array = cv2.resize(img, (224, 224))  # 이미지 크기 조정\n",
    "    img_array = np.expand_dims(img_array, axis=0)\n",
    "    img_array = preprocess_input(img_array)\n",
    "    # 특징 추출\n",
    "    features = base_model.predict(img_array)\n",
    "    return features\n",
    "\n",
    "def calculate_similarity(features1, features2):\n",
    "    # 코사인 유사도 계산\n",
    "    return cosine_similarity(features1, features2)[0][0]\n",
    "\n",
    "def draw_matches(img1, img2, keypoints1, keypoints2, matches):\n",
    "    # 매칭된 객체를 시각적으로 표시\n",
    "    matched_img = cv2.drawMatches(img1, keypoints1, img2, keypoints2, matches, None)\n",
    "    cv2.imshow(\"Matches\", matched_img)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "# 예제 이미지 경로\n",
    "img_path1 = 'path_to_image1.jpg'\n",
    "img_path2 = 'path_to_image2.jpg'\n",
    "# 이미지 불러오기\n",
    "img1 = cv2.imread(img_path1)\n",
    "img2 = cv2.imread(img_path2)\n",
    "# SIFT를 사용하여 키포인트와 디스크립터 추출\n",
    "sift = cv2.SIFT_create()\n",
    "keypoints1, descriptors1 = sift.detectAndCompute(img1, None)\n",
    "keypoints2, descriptors2 = sift.detectAndCompute(img2, None)\n",
    "# 매칭을 위한 BFMatcher 객체 생성\n",
    "bf = cv2.BFMatcher()\n",
    "matches = bf.knnMatch(descriptors1, descriptors2, k=2)\n",
    "# 좋은 매칭 필터링\n",
    "good_matches = []\n",
    "for m, n in matches:\n",
    "    if m.distance < 0.75 * n.distance:\n",
    "        good_matches.append(m)\n",
    "\n",
    "# 매칭된 객체 시각화\n",
    "draw_matches(img1, img2, keypoints1, keypoints2, good_matches)\n",
    "\n",
    "# 매칭된 객체들의 특징 추출 및 유사도 계산\n",
    "for match in good_matches:\n",
    "    img1_idx = match.queryIdx\n",
    "    img2_idx = match.trainIdx\n",
    "\n",
    "    # 매칭된 키포인트의 위치\n",
    "    (x1, y1) = keypoints1[img1_idx].pt\n",
    "    (x2, y2) = keypoints2[img2_idx].pt\n",
    "\n",
    "    # 매칭된 객체의 특징 추출\n",
    "    patch1 = img1[int(y1)-32:int(y1)+32, int(x1)-32:int(x1)+32]\n",
    "    patch2 = img2[int(y2)-32:int(y2)+32, int(x2)-32:int(x2)+32]\n",
    "\n",
    "    if patch1.shape == (64, 64, 3) and patch2.shape == (64, 64, 3):\n",
    "        features1 = extract_features(patch1)\n",
    "        features2 = extract_features(patch2)\n",
    "\n",
    "        similarity = calculate_similarity(features1, features2)\n",
    "        print(f\"두 객체의 유사도: {similarity}\")\n",
    "\n",
    "        # 유사도가 임계값 이상이면 같은 객체로 간주\n",
    "        threshold = 0.8\n",
    "        if similarity > threshold:\n",
    "            print(\"두 객체는 같은 객체일 가능성이 높습니다.\")\n",
    "        else:\n",
    "            print(\"두 객체는 다른 객체일 가능성이 높습니다.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "opencv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
